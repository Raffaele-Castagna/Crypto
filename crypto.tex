\documentclass[11pt, a4paper]{article}
\usepackage{amsmath, amsthm, amssymb, calrsfs, wasysym, verbatim, bbm, color, graphics, geometry}
\usepackage[utf8]{inputenc} % comment when using lualatex
%\usepackage[italian]{babel} % lingua e a-capo-sillabato
\usepackage{fullpage}
\usepackage{graphicx}
%\usepackage[hidelinks]{hyperref,xcolor} % link di pagina
\usepackage[bottom]{footmisc} % note appiccicate al fondo della pagina
\usepackage{float} % per posizionamento immagini
\usepackage{cancel}
\usepackage{tikz}
\usepackage{framed}
\usepackage{amsfonts}

\geometry{tmargin=.75in, bmargin=.75in, lmargin=.75in, rmargin = .75in}  

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\enc}{\mathcal{E}nc}
\newcommand{\dec}{\mathcal{D}ec}
\newcommand{\negl}{\text{negl}}
\newcommand{\poly}{\text{poly}}
\newcommand{\game}{\text{GAME}}
\newcommand{\Cdot}{\boldsymbol{\cdot}}

\newtheorem{thm}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{conv}{Convention}
\newtheorem{rem}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}



\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\title{Cryptography Notes }
\author{Raffaele Castagna}

\date{Academic Year 2025-2026}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Intro to Cryptography}
\label{Intro}
\subsection{Secure Communication}
We have multiple goals in cryptography, the most important ones being:
\begin{center}
    \textbf{Confidential Integrity}
    \includegraphics{img/CF comm.png}
\end{center}
\begin{center}
    \textbf{Message Integrity}
    \includegraphics{img/Msg int.png}
\end{center}
Basically we want our message to be both \textbf{confidential}, so no-one except the intended target sees it and we it to be unmodified, so that its \textbf{integrity} has not been compromised.\\\\
There are many different ways to do this, but in our case we only see two major ways:
\begin{itemize}
    \item \textbf{Symmetric Cryptography}:  $\text{Where Alice and Bob share a key } k \in \mathcal{K} \text{,the key is random and unknown to Eve}$
    \item \textbf{Assymetric Cryptography}: Where Alice and Bob do not share a key, but they have each their own key pair $(p_k,s_k)$ where $p_k$ is the public key and $s_k$ is the secret/private key
\end{itemize}

\subsection{Unconditional Security}
To achieve confidential communication, we use symmetric cryptography.
\begin{center}
    \includegraphics{img/US.png}
\end{center}
With $m \in \mathcal{M}, c \in \mathcal{C}, k \in \mathcal{K}$\\\\
In this case we have Alice sending a message \textit{m} which is then encrypted utilizing a randomly generate key \textit{k} to generate the cyphertext \textit{c}, after that to get back to the initial message \textit{m}, Bob will then need to decrypt it utilizing his own key \textit{k} on cyphertext \textit{c}.\\
In a more formal way we can define Symmetric encryption (SKE) as $\prod = (Enc, Dec)$ such that:
\begin{itemize}
    \item Enc : $\mathcal{M} \times \mathcal{K} \rightarrow \mathcal{C}$
    \item Dec: $\mathcal{C} \times \mathcal{K} \rightarrow \mathcal{C}$
    \item k is uniform over $\mathcal{K}$ (k is chosen according to some distribution)
\end{itemize}
An encryption scheme must satisfy the correctness requirement:
\begin{defn}
    $\forall k \in \mathcal{K}, \forall m \in \mathcal{M} \text{ it holds that } Dec(k,Enc(k,m)) = m$
\end{defn}

\textbf{Kerchoff's Principle}:
\begin{defn}
    Security should not depend on the secrecy of the algorithm but on the secrecy of the key.
\end{defn}
\subsection{Perfect Secrecy}
\begin{defn}
Let M be any distribution over $\mathcal{M}$ and K be uniform over $\mathcal{K}$ (Then observe C = Enc(K,M) in a distribution over C), we say that (Enc,Dec) = $\prod$ is \textbf{perfectly secret}
if $\forall M, \forall m \in \mathcal{M}, \forall c \in \mathcal{C}: Pr[M=m] = Pr(M=m | C=c)$ (The probability that M is m is equal to the probability that M is m knowing that C is c, so by knowing the cyphertext, we dont gain additional information).
\begin{lem}
The following are equivalent:
\begin{itemize}
    \item Perfect Secrecy
    \item M and C are independant
    \item $\forall m,m' \in \mathcal{M}, \forall c \in \mathcal{C}: Pr[Enc(k,m) = c] = Pr[Enc(k,m') = c] \text{ with k being uniform over } \mathcal{K}$
\end{itemize}
\end{lem}
\end{defn}
\subsection{OTP}
Let us see if OTP (\textit{One Time Pad}) is perfectly secret\\
We know that the OTP uses $\oplus$ to generate and later decypher the cyphertext, we have that $K=M=C=\{0,1\}^N$ with N being the length of the string, we know that:
\begin{itemize}
    \item Enc (k,m) = $k \oplus m$
    \item Dec (k,c) = $c \oplus k$ = $(k \oplus m) \oplus k = m$
\end{itemize}
To prove that it is perfectly secret let us utilize the third lemma:
\begin{center}
    $Pr[C=c | M=m'] = Pr[\text{Enc}_k (m') = c] = Pr[m' \oplus K = c] = Pr[K = m' \oplus c] = 2^{-N}$
\end{center}
and therefore:\\
\begin{center}
    $Pr[Enc(k,m') = c] = 2^{-N}$
\end{center}
There seem to be some limitations, the key can only be used once and it must as long as the message,lets assume we encrypt m'' and m':
$c_1 = k \oplus m_1\text{    } c_2 = k \oplus m_2 \text{ therefore } c_1 \oplus c_2 = m_1 \oplus m_2$, so if I know a pair $(m_1,c_1) \text{ then I could compute } m_2$, therefore we cannot encrypt two messages with the same key.
\begin{thm}[Shannon]
Let $\prod$ be any perfectly secret SKE then we have $|\mathcal{K}| \ge |\mathcal{M}|$.
\end{thm}
\begin{proof}
Take $\prod$ to be uniform over $\mathcal{M}$. Take any c s.t. Pr[C=c] $>$ 0.\\
Consider $\mathcal{M'} = \{Dec(k,c): k \in \mathcal{K}\}$ and assume $|\mathcal{K}| < |\mathcal{M}|$ by contraddiction, then:\\
\begin{center}
    $|\mathcal{M}|' \leq |\mathcal{K}| < |\mathcal{M}| \rightarrow |\mathcal{M'}| < |\mathcal{M}| \rightarrow \exists m \in \mathcal{M} \setminus \mathcal{M'}$
\end{center}
Now:\\
\begin{center}
   $ Pr[M=m] = |\mathcal{M}|^{-1} \text{ but } Pr[M=m | C=c] = 0 $
\end{center}

\end{proof}

\subsection{Proof that the lemmas imply eachother}
Let us prove that $1 \implies 2 \implies 3 \implies 1$\\\\
Let us start by proving that $1\implies2$:
\begin{proof}
We know that $Pr[M=m] = Pr[M=m|C=c] \rightarrow \frac{Pr[M=m \wedge C=c]}{Pr[C=c]} = Pr[M=m \wedge C=c] \\= Pr[M=m] * Pr[C = c]$
and therefore we have proved their independence, so $I(M;C) = 0$
\end{proof}
Let us prove that $2 \implies 3$
\begin{proof}
Let us fix an m from M and c from C:\\
$Pr[Enc(K,m) = c] = Pr[Enc(K,M) = c | M = m] \implies Pr[C = c | M = m] = Pr[C=c]$ \\Remember that Enc(...) is c!\\\\ We do the same thing for $m'$ and we get: 
$Pr[C=c | M=m] = Pr[C=c]$ for both of them.\\
Therefore: $Pr[Enc(K,m')= c] = Pr[C=c]$
\end{proof}

And now $3 \implies 1$:
Take any c from C:\\
$Pr[C=c] = Pr[C=c|M=m]$ by 2 (we are claiming this)\\\\
If the claim is true then:\\
$Pr[M=m|C=c] * Pr[C=c] = Pr[M=m \wedge C=c] = Pr[C = c | M = m] * Pr[M=m] \implies$\\\\
\begin{center}
   $\implies$ $Pr[M=m] = \frac{Pr[M=m | C=c] * \cancel{Pr[C=c]}}{\cancel{Pr[C=c|M=m]}}$

\end{center}
However we still need to prove the claim:\\
$$Pr[C=c] = \sum_{m'}^{}Pr[C=c \wedge M=m'] = \sum_{m'}^{}Pr[C=c | M=m'] * Pr[M=m'] =$$\\ $$\sum_{m'}^{}Pr[Enc(K,m') = c | M=m'] * Pr[M=m']\\= \sum_{m'}^{}Pr[Enc(K,m') = c] * Pr[M=m'] $$\\
$$ \sum_{m'}^{}Pr[Enc(k,m) = c] * Pr[M=m'] = Pr[Enc(k,m) = c] * \sum_{m'}^{}Pr[M=m'] \impliedby 1$$\\
$$ Pr[Enc(k,m) = c] = Pr[Enc(K,M) = c | M=m] \rightarrow Pr[C=c | M=m]$$
\subsection{Message Authentication Codes}
\begin{center}
    \includegraphics[scale=0.5]{img/MAC.png}
\end{center}
In case it is $\tau$ then we accept it, else no.\\
There is no need to prove correctness as $\tau$ is deterministic, so if we had the same k and m, we should get the same $\tau$\\\\
\textbf{Unforgeability}\\\\
It should be hard to forge $\tau'$ such on msg m' and it should be hard to produce (m,$\tau$) as long as m' $\neq$ m\\
\begin{defn}
\textbf{Statistical secure MAC} We say that $\prod$ = Tag has $\epsilon$-statistical security (unforgeability) if  $\text{ }\forall m,m'\text{ } \in \mathcal{M} \text{ with } m \neq m'\text{ } \forall \tau,\tau' \in \mathcal{T}$:\\
$$Pr[Tag(K,m') = \tau'\text{ } | \text{ }Tag(K,m)= \tau] \leq \epsilon$$
\end{defn}
\textbf{TLDR}: Fix \underline{any} m,m' with m' $\neq$ m take $\tau,\tau'$ on the condition that $\tau$ is tag of m and given $\tau'$, it is always less than or equal to $\epsilon$\\
Here $\epsilon$ is a parameter e.g. $2^{-80}$\\
\textbf{Exercise} Let us prove that it is impossible to get $\epsilon = 0$\\
Because a random $\tau' \in \mathcal{T}$ has probability $\geq \frac{1}{|\mathcal{T}|}$ to be correct it is impossible.\\\\
Note that the definition is valid for One-Time!\\
We will show:
\begin{itemize}
    \item The notion is Achievable
    \item It's inefficient, in fact:
\end{itemize}
\begin{thm}
    Any t-time $2^{-\lambda}$ statistically secure Tag has a key of some (t+1)*$\lambda$
\end{thm}
We will now show that any form of hash function with a particular property satisfies the definition.\\
\begin{defn}
    \textbf{Pairwise independence} A family $\mathcal{H} = \{h_k: \mathcal{M} \rightarrow \mathcal{T}\}_{k \in \mathcal{K}}$ is pairwise independant if: $\forall m,m' \in \mathcal{M} \text{s.t.} m \neq m'$ then:
    $(h(K,m),h(K,m'))$ is uniform over $\mathcal{T}^2 = \mathcal{T} \times \mathcal{T}$ for K uniform over $\mathcal{K}$
\end{defn}

\begin{thm}
    Any family $\mathcal{H}$ of pairwise independent functions directly gives a $\epsilon = \frac{1}{|\mathcal{T}|}-\text{statistically}$ secure MAC.
\end{thm}
\begin{proof}
    Fix any $m \in \mathcal{M}, \tau \in \mathcal{T}$:\\
    $$Pr[Tag(K,m) = \tau] =$$ \\$$ Pr_k[h(K,m)= \tau] = \frac{1}{|\mathcal{T}|}\text{ by pairwise independence}$$\\
    Similiarly, for any m,m' s.t. m $\neq$ m', $\tau,\tau' \in \mathcal{T}$.
    $$Pr_k[Tag(K,m)= \tau \wedge Tag(K,m') = \tau'] =$$
    $$Pr_k[h(K,m)=\tau \wedge h(K,m')= \tau'] = \frac{1}{|\mathcal{T}|^2}$$
    By Bayes:
    $$Pr[Tag(K,m')= \tau' | Tag(K,m) = \tau] = $$
    $$\frac{Pr[h(K,m;) = \tau' \wedge h(K,m) = \tau]}{Pr[h(K,m) = \tau]} =$$
    $$\frac{\frac{1}{|\mathcal{T}|^2}}{\frac{1}{|\mathcal{T}|}} = \frac{1}{|\mathcal{T}|}$$

\end{proof}
Now we need to instantiate it, here is a construction, Let p be a prime:\\
    $$h_{a,b}(m) = am+b \mod p $$
    $$k = (a,b) \in \Z_{p}^2 = \mathcal{K}$$
    $$\Z_p = \mathcal{M} =\mathcal{T}$$
\begin{lem}
    The above $\mathcal{H}$ is \textit{pairwise independant}.
\end{lem}
\begin{proof}
    For all $m,m' \in \Z_p , \tau,\tau' \in \Z_p$ with $m \neq m'$\\
    $$\Pr_{(a,b) \in \Z_{p}^2}[h_{a,b}(m) = \tau \wedge h_{a,b}(m') = \tau'] =$$
    $$\Pr_{(a,b) \in \Z_{p}^2}\left[
        \begin{pmatrix}
        m & 1 \\ m' & 1
        \end{pmatrix}
        \begin{pmatrix}
            a \\ b
        \end{pmatrix} =
        \begin{matrix}
            \tau \\ \tau'
        \end{matrix}\right] = $$ 
        $$\Pr_{(a,b) \in \Z_{p}^2}\left[
        \begin{pmatrix}
            a \\ b
        \end{pmatrix} =
        \begin{pmatrix}
        m & 1 \\ m' & 1
        \end{pmatrix}
        \begin{matrix}
            \tau \\ \tau'
        \end{matrix}\right] = $$
        $$\frac{1}{p^2} = \frac{1}{|\Z_{p}|^2} = \frac{1}{|\mathcal{T}|^2}$$
\end{proof}
\subsection{Randomness Extraction}
Alice and Bob need a \textbf{random} key, how can they generate it?\\
Randomness is crucial for crypto, and two components are necessary in any RNG (e.g. Fortuna, /dev/rand):\\
\begin{itemize}
    \item Randomness extraction: By measuring physical quantities we can get an \textbf{unpredictable} sequence of bits (Not necessarily uniform or for cheap!)\\ From this we extract a \textbf{random} Y which is short (e.g. 256 bits)
    \item Expand it to any amount (polynomial) using a psedorandom generator (PRG) - but this requires computational assumptions.
\end{itemize}
We want to understand how to extract from an unpredictable source X.\\
\textbf{Example \textit{Von Neumann Extractor}}
Assume $B \in {0,1} \text{ s.t. } \Pr[B=0] = p < \frac{1}{2}$.
\begin{itemize}
    \item Sample $b_1 \in B, b_2 \in B$
    \item if $b_1 = b_2$ then Resample
    \item Else output 1 $\iff b_1 = 0, b_2 = 1, \text{ or 0 if } b_1 = 1, b_2 =0$
\end{itemize}
Assuming it outputs something, this will be s.t.\\
$$\Pr[\text{Output 0}] = Pr[\text{Output 1}] = p*(1-p)$$
$$\Pr[\text{No output after N tries}] = (1-2p(1-p))^N \text{ which becomes small for large enough N}$$
We want to generalize this question, ideally we want to design a function Ext that takes a random variable X and outputs an uniform Ext(X), but this is impossible as the source must be unpredictable and Ext is deterministic
\begin{defn}[Min-Entropy]
    The min-entropy of X is: $H_{\infty} = - \log_2\max{\Pr[X=x]}$
\end{defn}
\textbf{Example}:
Let $X \equiv U_m$ Uniform over $\{0,1\}^{N}$. $ H_{\infty} (X) = N$\\
If X is a costant we have $H_\infty (X)$ = 0
\\\\
Here's the next best thing:\\
Design Ext that extracts UNIFORM $Y=Ext(X)$ for every X s.t. $H_\infty (X) \geq k$\\
But this is also impossible, even if $$Ext(X)= b \in \{0,1\}$$ $$k = n-1$$ $$x \in \{0,1\}^n$$\\
And here's why: fix any Ext:$\{0,1\}^n \rightarrow {0,1}$ and let $b \in {0,1}$ be the output of maximing $|Ext^{-1}(b)|$\\
\begin{center}
    \includegraphics[scale=0.3]{img/expl.png}
\end{center}
The bad X: Define X to be Uniform over $Ext^{-1}(b)$. Since it is uniform: $H_\infty(X) \geq n-1$ but $Ext(X) = b$ so not uniform.\\\\
Solution: Swap the quantifiers.
\begin{defn}[Seeded Extractor]
    A function $Ext: \{0,1\}^n \times \{0,1\}^d \rightarrow \{0,1\}$ is a (k,$\epsilon$)-seeded extractor if for every X over s.t. $H_\infty(X) \geq k$: $$(S,Ext(S,X)) \approx_\epsilon (S,U_e)$$
    for $S \equiv U_d$ (uniform over $\{0,1\}^d$). (Note that $(S,U_e) \equiv U_{d+e}$).
\end{defn}
What does this mean? There is a standard way to measure distance between distributions:
$$ Z \equiv_\epsilon Z' \iff SD(Z,Z') \leq \epsilon$$
$$ SD(Z,Z') = \frac{1}{2} \sum_{z} |Pr[Z=z] - Pr[Z'=z]|$$
This is equivalent: $\forall$ Unbounded adversary A:
$$|Pr[A(z)=1 : z \in Z] - Pr[A(z)=1 : z \in Z']| \leq \epsilon$$
\begin{thm}[Leftover Hash Lemma]
    Let $\mathcal{H} = \{h_s: \{0,1\}^n \rightarrow \{0,1\}^l\}_{s \in \{0,1\}^d}$ be a family of pairwise independent hash functions. Then Ext(x,s) = $h_s(x)$ is a (k,$\epsilon$)-seeded extractor for k $\geq l + 2\log_2(\frac{1}{\epsilon})$-2.

\end{thm}
\begin{lem}
    Let Y be a RV over $\mathcal{Y}$. Such that:
    $$Col(Y) = \sum_{y \in \mathcal{Y}} Pr[Y=y]^2 \leq \frac{1}{|\mathcal{Y}|} * (1 + 4\epsilon^2)$$
    Then, SD(Y,U) $\leq \epsilon$
\end{lem}
\begin{proof}
    $$SD(Y,U) = \frac{1}{2} \sum_{y \in \mathcal{Y}} |Pr[Y=y] - \Pr[U=y]|$$
    $$\frac{1}{2} \sum_{y \in \mathcal{Y}} |Pr[Y=y] - \frac{1}{|\mathcal{Y}|}|$$
    $$\text{Let } q_y = Pr[Y=y] - \frac{1}{|\mathcal{Y}|}$$
    $$\text{Let } s_y = \begin{cases}
        1 \text{ if } q_y \geq 0\\
        -1 \text{ else}
    \end{cases}$$
    $$\text{Hence } SD(Y,U) = \frac{1}{2} \sum_{y \in \mathcal{Y}} s_y q_y$$
    $$= \frac{1}{2} \langle s,q \rangle \leq \frac{1}{2} \sqrt{<\overrightarrow{q},\overrightarrow{q}> * <\overrightarrow{s},\overrightarrow{s}>} \text{ by Cauchy-Schwarz}$$
    $$ = \frac{1}{2} \sqrt{\sum_{y \in \mathcal{Y}} q_y^2 * |\mathcal{Y}|}$$

Now, We analyze the term $\sum_{y \in \mathcal{Y}} q_y^2$:
$$\sum_{y \in \mathcal{Y}} q_y^2 = \sum_{y \in \mathcal{Y}} (Pr[Y=y] - \frac{1}{|\mathcal{Y}|})^2 =$$
$$\sum_{y \in \mathcal{Y}} Pr[Y=y]^2 + \frac{1}{|\mathcal{Y}|^2} -2\frac{Pr[Y=y]}{|\mathcal{Y}|} =$$
$$ \underbrace{\sum_{y \in \mathcal{Y}} \Pr[Y=y]^2}_{Col(Y)} + \frac{1}{|\mathcal{Y}|} - 2\frac{1}{|\mathcal{Y}|} =$$
$$Col(Y) - \frac{1}{|\mathcal{Y}|} \leq \frac{4\epsilon^2}{|\mathcal{Y}|}$$
Then:
$$SD(Y,U) \leq \frac{1}{2} \sqrt{\frac{4\epsilon^2}{\cancel{|\mathcal{Y}|}} * \cancel{|\mathcal{Y}|}} = \epsilon$$
\end{proof}
Next we apply the lemma to prove the Leftover Hash Lemma:
\begin{proof}
    $$Y = (S,Ext(X,S)) = (S,h(S,X))$$
and compute Col(Y):
$$Col(Y) = \sum_{y \in \mathcal{Y}}\Pr[Y=y]^2 = \Pr[Y=Y']$$
$$= \Pr[S=S' \wedge h(S,X) = h(S',X')]$$
$$= \Pr[S=S' \wedge h(S,X) = h(S,X')]$$
$$= \Pr[S=S'] * \Pr[h(S,X) = h(S,X')]$$
$$= \frac{1}{2^d} * \Pr[h(S,X) = h(S,X')]$$
$$ = \frac{1}{2^d} * (\Pr[X=X'] + \Pr[h(S,X) = h(S,X') \wedge X \neq X'])$$
$$ \leq \frac{1}{2^d} * (\frac{1}{2^k} + \frac{1}{2^l}) \text{ by pairwise independence and } H_\infty(X) \geq k$$
$$ = \frac{1}{2^{d+l}}(1 + 2^{l-k}) \leq \frac{1}{2^{d+l}}(2^{2-2\log_2(\frac{1}{\epsilon})}+ 1)$$
$$ = \frac{1}{|\mathcal{Y}|} * (1 + 4\epsilon^2)$$ 
\end{proof}
\section{Computational Security}
We know that withouth any assumptions we can do Symmetric crypto and randomness generation, with some strong limitations.\\
\begin{itemize}
    \item Privacy: $|msg| = |key|$ and one-time use
    \item Integrity: same as above.
    \item Randomness We can't extract more than k from $p_y k$
\end{itemize}
We want to overcome all these limitations. We'll do so off of the base of some assumptions
\begin{itemize}
    \item Adversary is Computationally Bounded
    \item Hard Problems exist
\end{itemize}
We will make conditional statements:
\begin{thm}
    If Problem X is hard (against efficient solvers), Then cryptosystem $\prod$ is secure (against efficient adversaries)
\end{thm}
Consequence: if $\prod$ is insecure, $\exists$ efficient solver for X!\\
Depending on what X is, the above could be \textbf{Groundbreaking}.\\\\
\textbf{Examples}:\\
X = $"P \neq NP"$
X = "Factoring is hard"\\
X = "Discrete Log is hard"\\\\
We are not able to just assume $P \neq NP$, we need a stronger assumption:
\textbf{One-Way Functions}: These are functions that are easy to compute but hard to invert.\\
Clearly OWF$ \implies P \neq NP$, why?\\
Because if $P=NP$, OWF do not exist as checking if f(x) = y is efficient and this it's in NP=P\\
We cannot exclude that $P \neq NP$ but still,OWF do not exist.\\\\
To better demonstrate this, we can refer to the following worlds created by Russel Impagliazzo:
\begin{itemize}
    \item Algorithmica: P=NP
    \item Heuristica: P $\neq$ NP but no "average-hard" problems
    \item Pessiland: $P\neq NP$ and "average-hard" problems exist, but no OWF
    \item Minicrypt: OWFs exist
    \item Cryptomania: OWF exist + Public-key crypto exist
\end{itemize}
First we must start by fixing a model of computation: Turing Machines\\
efficient computation = polynomial time TMs.\\
Let's be generous: Adversaries can use any amount (polynomial) of randomness: Probabilistic Polynomial Time (PPT) TMs.\\
In what comes next we could define two approaches:
\begin{itemize}
    \item \textbf{Concrete Security} Security hols w.r.t. t-time Tms except w.p. $\leq \epsilon$ (e.g.  $t= 2^20$ steps, $\epsilon = 2^{-80}$)
    \item \textbf{Asymptotic Security} Let $\lambda$ be a security parameter. Adversaries are poly($\lambda$)-time PPT TMs ($\epsilon$ = negligeble $=$ negl($\lambda$))\\
\end{itemize}
\begin{defn}[Negligible]
    $\epsilon: \N \rightarrow \R$ is negligible if $\forall p(\lambda)=\text{poly}(\lambda) \text{ } \exists \lambda_0 \in \N \text{ s.t. } \forall \lambda > \lambda_0: \epsilon(\lambda) \leq \frac{1}{p(\lambda)}$
\end{defn}
(In other words, $\epsilon(\lambda) \leq O(\frac{1}{p(\lambda)}) \text{  }\forall p(\lambda) = \text{poly}(\lambda))$\\
\subsection{Pseudorandomness}
This is our first step towards efficient symmetric crypto. Moreover, pseudorandomness is used in modern computers to simulate real randomness. We will see that OWF are enough for pseudorandomness.\\
\begin{defn}[OWF]
    A function $f :\{0,1\}^n \rightarrow \{0,1\}^n$ is One-Way, if: $\forall PPT \mathcal{A}$:
    $$\Pr_{x \leftarrow\{0,1\}^n}[f(x')= y : y = f(x); x' \leftarrow \mathcal{A}(y)] \leq \text{negl}(n)$$
\end{defn}
Informally, it goes to zero faster than any inverse of a polynomial function.\\\\
Example of negl(n) is $2^{-n}$\\
An alternative way to think about it:
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/Alternative1.png}
\end{center}
\begin{defn}[Pseudorandomness]
    Pseudorandomness is a sequence of bits that are not random, but look random. We capture this requirement using \textbf{Indistinguishability (computational)}.\\
    We have already seen something like this in SD. Given X,X' RVs over some domain, SD(X,X') $\leq \epsilon$ is equivalent to: $\forall \mathcal{D}$ (adversary):
    $$|Pr[\mathcal{D}(x)=1 : x \leftarrow X] - Pr[\mathcal{D}(y)=1 : y \leftarrow X']| \leq \epsilon$$ 
\end{defn}
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/Alt2.png}
\end{center}
\begin{defn}
    X ($X_n$),Y ($Y_n$) are computationally indistinguishable ($ X \approx_c Y$) if $\forall PPT \mathcal{D}$:
    $$|Pr[\mathcal{D}(z)=1 : z \leftarrow X_n] - Pr[\mathcal{D}(z)=1 : x' \leftarrow Y_n]| \leq \text{negl}(n)$$
\end{defn}
With this we can define pseudorandomness:
\begin{defn}[Pseudorandom Generator (PRG)]
    A function $G: \{0,1\}^n \rightarrow \{0,1\}^{n+l}$ with $l \geq 1$ (The Stretch) is secure if:
    $$G(U_n) \approx_c U_{n+l}$$
    $$U_n \equiv \text{ uniform over } \{0,1\}^n$$
    $$U_{n+l} \equiv \text{ uniform over } \{0,1\}^{n+l}$$
\end{defn}
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/pseudogen.png}
\end{center}
Let's understand how to build PRGs:
\begin{itemize}
    \item Use a randomness extractor to get a uniform seed $s \in \{0,,1\}^n$.
    \item Define a simple PRG $G:\{0,1\}^n \rightarrow \{0,1\}^{n+1}$ with minimal stretch $l = 1$.
    \item Use G to stretch any $l(n) = poly(n)$.
\end{itemize}
Theory vs Practice:
\begin{itemize}
    \item Randomness extraction is what we already studied. But in practice it is done using Hash Functions.
    \item Theoretical G can be obtained from any OWF. Practical G is Heuristic
    \item Stretch is the same
    \item In practice the seed is refreshed periodically collecting new entropy
\end{itemize}
\begin{thm}
    If there exists a PRG $G: \{0,1\}^n \rightarrow \{0,1\}^{n+1},\text{ then there exists a PRG } G^l : \{0,1\}^n \rightarrow \{0,1\}^{n+l} \text{ for any } l(n)=poly(n) $
\end{thm}
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/BlueGen.png}
\end{center}
\begin{proof}
    Assume $G^l$ not secure, $\exists$ PPT $\mathcal{D}^l$ that can distinguish $G^l(U_n)$ from $U_{n+l}$ with probability $\geq \frac{1}{p(n)}$ for some polynomial. We want to buildt PPT $\mathcal{D}$ that can
    distinguish $G(U_n)$ from $U_{n+1}$ with probability $\frac{1}{p(n)}$. ($\mathcal{D}$ is called a reduction)
    \begin{center}
        \includegraphics[scale=0.4]{img/Comp_sec/Hybrid_arg_img.png}
    \end{center}
\section*{Hybrid argument}

\[
H_0(n) \equiv G^{n}(U_m)
\]

\[
b_1, \ldots, b_\ell \leftarrow \{0,1\}^\ell
\]

\[
H_i(M) \equiv
\begin{cases}
b_1, \ldots, b_i \leftarrow \{0,1\} \\
s_i \leftarrow \{0,1\}^n \\
(b_{i+1}, \ldots, b_\ell, s_\ell) = G(s_i)
\end{cases}
\]

\[
H_\ell(n) \equiv U_{\ell + m}
\]

\end{proof}

\begin{lem}
    $\forall i : H_i \approx_c H_{i+1}$.
\end{lem}
\begin{proof}
    By reduction (as before):
    \begin{center}
        \includegraphics[scale=0.4]{img/Comp_sec/Reduction.png}
    \end{center}
    By the above observations:
    $$\Pr[\mathcal{D}(z) = 1: z = G(s); s \in \{0,1\}^n] $$
    $$= \Pr[\mathcal{D}'(b1,\dots,b_\ell,s_\ell) = 1 : (b1,\dots,b_\ell,s_\ell) \in H_i (n)]$$
    $$ \Pr[\mathcal{D}(z) = 1 : z \leftarrow U_{n+1}] = \Pr[\mathcal{D}' (b1,\dots,b_\ell,s_\ell) = 1 : (b1,\dots,b_\ell,s_\ell) \in H_{n+1}(n)] \implies $$
    $$ |\Pr[\mathcal{D}(z)=1 : z = G(U_n)] - \Pr[\mathcal{D}(z) = 1: z \in U_n+1]| \geq \frac{1}{p'(n)}.$$
    $$\implies H_i \approx_c H_i + 1$$
\end{proof}
The next question is: How do we build G : $\{0,1\}^n \rightarrow \{0,1\}^{n+1}$?\\
\begin{itemize}
    \item Practical: Heuristic construction
    \item Theoretical: From any OWF
\end{itemize}
So we need to build a PRG from a OWF. 
To do so we need to introduce the concept of \textbf{Hardcore bits}. They are bits of info about x that are hard to compute given $y=f(x)$.
It's a predicate $h(x)$ s.t. $h(x) \in \{0,1\}$ is \textbf{hard} to compute given $f(x)$ (w.p. better than $\frac{1}{2}$).\\
First: Can there be a single h such that h is hardcore for all OWF?\\
No, because suppose we fix any h; Take f for a OWF, consider:
$$\hat{f}(x) = h(x) || f(x)$$.
h is not hard-core for $\hat{f}$, but is $\hat{f}$ a OWF?\\
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/f_hat1.png}
\end{center}
$$\Pr[\hat{\mathcal{A}} \text{ wins }] \geq (\frac{1}{2} * \Pr[\hat{\mathcal{A}}(h(x) || y) \text{ wins }])$$
$$\Pr[\hat{\mathcal{A}} \text{ wins }] = \Pr[\hat{\mathcal{A}}(b,y) \text{ wins } \wedge b = h(x)] + \Pr[\hat{\mathcal{A}}(b,y) \text{ wins } \wedge b \neq h(x)]$$
$$ \geq \frac{1}{2} * \Pr[\hat{\mathcal{A}}(h(x),y) \text{ wins }]$$
$$ \geq \frac{1}{2} * \frac{1}{\text{poly}}$$

Solution: swap the quantifiers.
\begin{defn}
    Let $f : \{0,1\}^n \rightarrow \{0,1\}^n$ be a OWF. Then h is hard-core for f if either of the following is true:
    \begin{itemize}
        \item $\forall \text{ PPT } \mathcal{P}\colon \Pr[\mathcal{P}(y) = h(x): \substack{x \leftarrow \{0,1\}^n \\ y = f(x)}] \leq \frac{1}{2}$
        \item $(f(x),h(x)) \approx_c (f(x),b)$ for $b \leftarrow \{0,1\}$ and $x \leftarrow \{0,1\}^n$
    \end{itemize}
\end{defn}
\begin{proof}
We show that the following are equivalent for a predicate $h$ and a function $f$:
\begin{enumerate}
    \item For all PPT algorithms $\mathcal{P}$,
    \[
        \Pr\left[\mathcal{P}(y) = h(x) : x \leftarrow \{0,1\}^n,\, y = f(x)\right] \leq \frac{1}{2} + \text{negl}(n)
    \]
    \item $(f(x), h(x)) \approx_c (f(x), b)$, where $b \leftarrow \{0,1\}$ is uniform and $x \leftarrow \{0,1\}^n$.
\end{enumerate}

\textbf{(2) $\implies$ (1):} \\
Suppose $(f(x), h(x)) \approx_c (f(x), b)$. Assume, for contradiction, that there exists a PPT $\mathcal{P}$ such that
\[
    \Pr[\mathcal{P}(f(x)) = h(x)] \geq \frac{1}{2} + \epsilon
\]
for some non-negligible $\epsilon$. Construct a distinguisher $\mathcal{D}$ that, given $(y, b')$, outputs $1$ if $\mathcal{P}(y) = b'$, else $0$. Then:
\[
    \left| \Pr[\mathcal{D}(f(x), h(x)) = 1] - \Pr[\mathcal{D}(f(x), b) = 1] \right| = \left| \Pr[\mathcal{P}(f(x)) = h(x)] - \Pr[\mathcal{P}(f(x)) = b] \right|
\]
But $\Pr[\mathcal{P}(f(x)) = b] = \frac{1}{2}$ since $b$ is uniform and independent. Thus, the advantage is at least $\epsilon$, contradicting computational indistinguishability.

\end{proof}
It also true that $1 \implies 2$.\\
\begin{thm}
    If one-way permutations exist (OWP), then there exist $f\colon\{0,1\}^n \rightarrow \{0,1\}^n$, then $\exists G\colon\{0,1\}^n \rightarrow\{0,1\}^{n+1}$ PRG.
\end{thm}
\begin{proof}
    $$G(s) = f(s) || h(s) \text{ where h is hard-core for f.}$$
    $$G(U_n) \equiv f(U_n) || h(U_n) \approx_c f(U_n) || U_1 \equiv U_{n+1}$$
\end{proof}
\begin{thm}
    If OWF exist, then PRGs with $l(n) = 1$ exist.
\end{thm}
All that is left is to build h for every given f.\\
\begin{thm}[Goldreich-Levin]
    Let $f\colon\{0,1\}^n \rightarrow \{0,1\}^n$ be a OWF $g\colon\{0,1\}^{2n} \rightarrow \{0,1\}^{2n}$ with hardcore predicate:
    $$h(x,r) = \oplus_{i=1}^{n}  x_i * r_i =\text{ } <\vec{x,r}>\mod 2$$
\end{thm}
\begin{proof}
    Proof ideas: If $\exists \text{ PPT } \mathcal{P}$ for $h(x,r)$, then $\exists$ PPT $\mathcal{A}$ breaking g, in particular $\mathcal{A}$ can find x.\\
    Simple cases:\\\\
    Assume $\mathcal{P}$ is super good: $\forall x,r \Pr[\mathcal{P}(y) = h(x,r)] = 1$\\
    Then $\mathcal{A}$ will just run $\mathcal{P}$ on 
     \[
\ y_1 = \left( f(x),\, \vec{e}_1 \right)
\]
\[
\ y_2 = \left( f(x),\, \vec{e}_2 \right)
\]
\[
\vec{e}_i = (0\,\cdots\,0\,1\,0\,\cdots) \quad \text{($1$ in position $i$, $0$ elsewhere)}
\]
Second idea: Assume $\mathcal{P}$ is very good: $\forall x \in \{0,1\}^n$:\\
$$\Pr_{r \leftarrow \{0,1\}^n}[\mathcal{P}(f(x),r) = h(x,r)] \geq \frac{3}{4} + \frac{1}{\text{poly}}$$
Run $\mathcal{P}$ on r random and $r \oplus e_i$.
$$x_i = <x,r\oplus e_i> \oplus <x,r> = <x,e_i>$$
Still you can amplify by taking majority of many queries.
\end{proof}
\subsection{Symmetric Key Encryption}
Recap from: $G$ is a Pseudorandom Generator (PRG) with stretch $l(\lambda) = \poly(\lambda)$.

Today, we will apply what we have learned to Symmetric Key Encryption (SKE).

Let us apply what we have learned to SKE, simple idea:
\begin{itemize}
    \item \textbf{Encryption}: $\enc(k, m) = G(k) \oplus m = c$
    \item \textbf{Decryption}: $\dec(k, c) = G(k) \oplus c = m$
\end{itemize}
$k \in \{0,1\}^\lambda$, but $m \in \{0,1\}^{\lambda + l}$ for any l = poly.

What does it mean for the above scheme to be computationally secure? Let's start with a warm-up definition.

\begin{defn}[One-Time Computational Security for SKE]

Let $\Pi = (\enc, \dec)$ be a Symmetric Key Encryption scheme. We say $\Pi$ is \textbf{one-time computationally secure} if:\\
$$ \game_{\Pi, \mathcal{A}}^{1\text{-time}}(\lambda, 0) \approx_c \game_{\Pi, \mathcal{A}}^{1\text{-time}}(\lambda, 1) $$
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/example1.png}
\end{center}
Recall this means:
$$|\Pr[b' = 1\colon \game_{\Pi, \mathcal{A}}^{1\text{-time}}(\lambda, 0)] - \Pr[b' = 1\colon \game_{\Pi, \mathcal{A}}^{1\text{-time}}(\lambda, 1)]| \leq \text{negl}(\lambda)$$
\end{defn}
Why is this definition good? Because it captures natural properties every SKE has:

This definition captures several natural properties that a secure SKE should have:
\begin{itemize}
    \item It should be hard to compute the secret key.
    \item It should be hard to compute the entire message.
    \item It should be hard to compute even the first bit of the message.
\end{itemize}


On the negative side, this notion is strictly for a \textbf{one-time} scenario (i.e., one key, one message). If the same key is used to encrypt two different messages:
\begin{align*}
    c_1 &= G(k) \oplus m_1 \\
    c_2 &= G(k) \oplus m_2
\end{align*}
Then an adversary can compute $c_1 \oplus c_2 = (G(k) \oplus m_1) \oplus (G(k) \oplus m_2) = m_1 \oplus m_2$. If the adversary knows $m_1$, they can easily recover $m_2$.


\begin{thm}
    If $G$ is a PRG, then the scheme $\Pi$ defined by $\enc(k,m) = G(k) \oplus m$ is one-time computationally secure.
\end{thm}
\begin{proof}
    Starting with the initial experiment $\game(\lambda,b) \equiv \game_{\Pi, \mathcal{A}}^{1\text{-time}}(\lambda, b)$, we will introduce a hybrid experiment $\text{HYB}(\lambda, b)$ and show that:
    \begin{center}
        \includegraphics[scale=0.5]{img/Comp_sec/HYb.png}
    \end{center}
    Easy to see that $\text{HYB}(\lambda, 0) \equiv \text{HYB}(\lambda, 1)$ (perfect indistinguishability) because the distribution of $c$ is uniform and independant of b.\\
    On the other hand: $\game(\lambda, b) \approx_c \text{HYB}(\lambda, b) \forall b \in \{0,1\}$ (computational indistinguishability). By reduction: assume $\exists PPT \mathcal{A}$ such that:\\
    $$|\Pr[\game(\lambda,b = 1)] - \Pr[\text{HYB}(\lambda,b)= 1]| \geq \frac{1}{p(\lambda)}$$
    Then build PPT $\mathcal{A}_{prg}$ against $G$:
    \begin{center}
        \includegraphics[scale=0.4]{img/Comp_sec/red2.png}
    \end{center}
    By inspection:\\
    \[
\Pr\left[ b' = 1 : z \leftarrow G(U_\lambda) \right] = \Pr\left[ b' = 1 : \game(\lambda, b) \right]
\]
\[
\Pr\left[ b' = 1 : z \leftarrow U_{\lambda + l} \right] = \Pr\left[ b' = 1 : \text{HYB}(\lambda, b) \right]
\]
\[
\implies \left| \Pr\left[ b' = 1 : z \leftarrow G(U_\lambda) \right] - \Pr\left[ b' = 1 : z \leftarrow U_{\lambda + l} \right] \right| \geq \frac{1}{p(\lambda)}
\]

\[
\implies\ \game(\lambda, 0) \approx_c \text{HYB}(\lambda, 0)
\]
\[
\equiv\ \text{HYB}(\lambda, 1)
\]
\[
\approx_c\ \game(\lambda, 1)
\]
\[
\implies\ \game(\lambda, 0) \approx_c \game(\lambda, 1)
\]
\end{proof}

Our Next goal: Chosen-Plaintext Attack (CPA) Security.
\begin{defn}
    Let $\Pi = (\enc, \dec)$ be an SKE scheme. We say $\Pi$ is \textbf{CPA-secure} (secure against chosen-plaintext attacks) if for any PPT adversary $\mathcal{A}$:
    $$ \game_{\Pi, \mathcal{A}}^{\text{CPA}}(\lambda, 0) \approx_c \game_{\Pi, \mathcal{A}}^{\text{CPA}}(\lambda, 1) $$

\end{defn}
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/CPA.png}
\end{center}


\textbf{Observation}: No deterministic SKE can be CPA-secure. An adversary could query the oracle on $m_0^*$ to get $c_0$, then submit $(m_0^*, m_1^*)$ as the challenge. If the challenge ciphertext $c^*$ equals $c_0$, it knows $b=0$. Therefore, CPA-secure encryption must be randomized or stateful.

The previous one-time scheme is not CPA-secure because it is deterministic. We need a new tool.
\begin{defn}[Pseudorandom Function (PRF)]
    
\end{defn}
A function family $\mathcal{F} = \{F_k : \{0,1\}^n \to \{0,1\}^n\}_{k \in \{0,1\}^\lambda}$ is a PRF if:
$$\game_{\mathcal{F},\mathcal{A}}^{\text{prf}}(\lambda,0) \approx_c \game_{\mathcal{F},\mathcal{A}}^{\text{prf}}(\lambda,1)$$
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/prf.png}
\end{center}
Note: R is not efficiently computable as it takes exponential space to store it. $F(k,x)$ instead is efficiently computable for all k,x.\\
Plan:
\begin{enumerate}
    \item Build a PRF.
    \item Use it to get CPA secure SKE and more!
\end{enumerate}
How to build a PRF?
\begin{enumerate}
    \item Practice: many examples like DES, AES (more accurately, PRP, pseudorandom permutations, which are invertible PRFs).
    \item Theory: The existence of OWF implies the existence of PRG, which in turn implies the existence of PRF.
    $$OWF \implies PRG \implies PRF \implies PRP$$
\end{enumerate}
We cover our construction of PRFs.

\begin{defn}[The Goldreich-Goldwasser-Micali (GGM) Construction]
We will show one construction that proves PRGs imply PRFs:\\
The GGM tree, basically, its a proof that $PRG \implies PRF$.
Let $G: \{0,1\}^n \to \{0,1\}^{2n}$ be a PRG. We can split its output into two halves: $G(s) = (G_0(s), G_1(s))$, where $|G_0(s)| = |G_1(s)| = n$.


In other words:
$$ F_k(x_1x_2...x_n) = G_{x_n}(G_{x_{n-1}}(...G_{x_1}(k)...)) $$

Think of $G$ as $F(k,x)$ for $x \in \{0,1\}$.
\begin{center}
\includegraphics[scale=0.4]{img/Comp_sec/PRF2.png}
\end{center}

\begin{center}
\begin{tikzpicture}[level distance=1.5cm,
  level 1/.style={sibling distance=4cm},
  level 2/.style={sibling distance=2cm}]
  \node {$k$}
    child {node {$G_0(k)$}
      child {node {$G_0(G_0(k))$}}
      child {node {$G_1(G_0(k))$} edge from parent node[right] {1}}
      edge from parent node[left] {0}
    }
    child {node {$G_1(k)$}
      child {node {$G_0(G_1(k))$}}
      child {node {$G_1(G_1(k))$} edge from parent node[right] {1}}
      edge from parent node[right] {1}
    };
\end{tikzpicture}
\end{center}
In general:\\
$$ F_k(x_1x_2...x_n) = G_{x_n}(G_{x_{n-1}}(...G_{x_1}(k)...)) $$
\end{defn}
\begin{thm}
    If $G$ is a secure PRG, then the GGM construction $F$ is a secure PRF. $\mathcal{F} = \{ f_k \}$ is a PRF.
\end{thm}
The proof relies on a hybrid argument and the following lemmas.

\begin{itemize}
    \item \textbf{Lemma 1}: If $G: \{0,1\}^n \to \{0,1\}^{2n}$ is a PRG, then for any polynomial $t(\lambda)$, the following two ensembles are computationally indistinguishable:
    $$ \{ (G(k_1), ..., G(k_t)) \} \approx_c \{ (U_{2n}, ..., U_{2n}) \}$$
    $$ k_1, ... , k_t \leftarrow U_n $$
    Next, given $F'_k \colon \{0,1\}^{n-1} \to \{0,1\}^n$ a PRF, then define:
    $$ F_k(x,y) = G_x(F'_{k}(y)) \text{ with } x \in \{0,1\}, y \in \{0,1\}^{n-1} $$
    \item \textbf{Lemma 2}: If $F'_k$ is a secure PRF, then $F_k$ is also a secure PRF.
\end{itemize}
Recall the GGM (Goldreich-Goldwasser-Micali) construction: 
$$ G:\{0,1\}^{\lambda}\rightarrow\{0,1\}^{2\lambda} $$ 
$$ G(k)=(G_{0}(k),G_{1}(k)) $$ 

We build $\mathcal{F}=\{F_{k}:\{0,1\}^{n(\lambda)}\rightarrow\{0,1\}^{\lambda}\}$ with $k \in \{0,1\}^{\lambda}$ such that 
$$ F_{k}(x)=G_{x_{n}}(G_{x_{n-1}}(...G_{x_{1}}(k)...)) $$ 
where $x = x_1x_2...x_n \in \{0,1\}^n$.

\subsection*{Proof of Security (by Induction)}

For the proof, let $n(\lambda) = \poly(\lambda)$. We use induction on $n$. 

Let $F_{k}^{'}:\{0,1\}^{n-1}\rightarrow\{0,1\}^{\lambda}$ be the GGM construction for inputs of length $n-1$. 
We can write $F_k$ for $n$-bit inputs as:
$$ F_{k}(x,y)=G_{x}(F_{k}^{'}(y)) $$ 
where $x\in\{0,1\}$ and $y\in\{0,1\}^{n-1}$. 

\begin{lem} 
If $\{F_{k}^{'}\}$ (GGM on $n-1$ inputs) is a PRF, then $\{F_k\}$ (GGM on $n$ inputs) is also a PRF family. 
\end{lem}

We can use this lemma to prove the security of GGM by induction. 

\subsubsection*{Base Case ($n=1$)} 
For $n=1$, the GGM construction is: 
$$ F_{k}(x)=G_{x}(k), \quad x \in \{0,1\} $$ 
This is:
$$ F_k(x) = \begin{cases} G_0(k) & \text{if } x=0 \\ G_1(k) & \text{if } x=1 \end{cases} $$ 
This is a PRF because $G$ is a PRG, so $(G_{0}(k),G_{1}(k))\approx_{c}U_{2\lambda}$. An adversary querying $F_k(0)$ and $F_k(1)$ just gets the output of the PRG, which is indistinguishable from two random $\lambda$-bit strings $R(0)$ and $R(1)$.

\subsubsection*{Inductive Step}
Assume $\{F_{k}^{'}\}$ (GGM on $n-1$ inputs) is a PRF. We want to prove $\{F_k\}$ (GGM on $n$ inputs) is a PRF. This is exactly what the Lemma states. 

\begin{proof}[Proof (of Lemma)] 
We use a hybrid argument. Let $\mathcal{A}$ be a PPT adversary.

\begin{itemize}
    \item \textbf{HYB 0}: The real world. 
    $$ z = F_{k}(x,y) = G_{x}(F_{k}^{'}(y)) $$ 
    where $k \leftarrow U_{\lambda}$. 
    
    \item \textbf{HYB 1}: 
    $$ z = G_{x}(R^{'}(y)) $$ 
    where $R^{'}: \leftarrow \mathcal{R}(\lambda,n-1 \rightarrow \lambda)$ is a truly random function from.
    
    \item \textbf{HYB 2}: The ideal world. 
    $$ z = R(x,y) $$ 
    where $R: \leftarrow \mathcal{R}(\lambda,n \rightarrow \lambda)$ is a truly random function.
\end{itemize}

\paragraph{Step 1: $HYB_0 \approx_c HYB_1$} 
We show $HYB_{0}(\lambda)\approx_{c}HYB_{1}(\lambda)$ by reduction. 
Assume a PPT $\mathcal{A}_{01}$ distinguishes $HYB_0$ and $HYB_1$ with non-negligible probability. 
We build a reduction $\mathcal{A}_{prf}$ that breaks the PRF security of $\{F_{k}^{'}\}$. 
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/Aprf.png}
\end{center}
If z = $F_{k}^{'}(y)$, then $G_{x}(z)$ is identical to what $\mathcal{A}_{prf}$ receives in $HYB_0$. On the other hand, if z = $R^{'}(y)$, then $G_{x}(z)$ is identical to what $\mathcal{A}_{prf}$ receives in $HYB_1$.\\
\paragraph{Step 2: $HYB_1 \approx_c HYB_2$} 
Here, we use the property that $G$ is a PRG. 

\begin{lem}[PRG Expansion]
If $G:\{0,1\}^{\lambda}\rightarrow\{0,1\}^{2\lambda}$ is a PRG, then for any $t = \poly(\lambda)$: 
$$ (G(k_{1}),\dots,G(k_{t})) \approx_{c} (U_{2\lambda},\dots,U_{2\lambda}) \equiv U_{2\lambda \cdot t} $$ 
where $k_{1},\dots,k_{t} \leftarrow U_{\lambda}$ are chosen independently. 
\end{lem}

Now, assume a PPT $\mathcal{A}_{12}$ distinguishes $HYB_1$ and $HYB_2$. We build a PPT $\mathcal{A}_{prg}$:breaking the above claim.
\begin{center}
    \includegraphics[scale=0.4]{img/Comp_sec/claim.png}
\end{center}
Let $t(\lambda) = q(\lambda)$ - the number of queries made by $\mathcal{A}_{12}$. Each of $z_i \in \{0,1\}^{2\lambda}$ and we can think of it as:
$$ z_i = (z_{i}^0, z_{i}^1) $$
With each corresponding to $\lambda$ bits.\\

In the above reduction, $i(y)$ is the index of the sample $z_i$ that was used when $\mathcal{A}_{12}$ asked already for x,y. If it never asked use the next available $z_i$.

\end{proof}

In the next few lectures, we'll see PRFs are enough to do practical symmetric crypto: 
\begin{itemize}
    \item CPA-Secure SKE (Symmetric Key Encryption) for messages of variable length (VIL). 
    \item MACs (Message Authentication Codes) for messages of VIL. 
    \item Non-malleable SKE (a.k.a. CCA-Secure SKE), which is equivalent to combining message privacy and message authentication. 
\end{itemize}

It will be important that our PRF $F$ is a \textbf{PRP (Pseudorandom Permutation)}, namely it is an efficient, length-preserving permutation for a given key. 
In practice, we call it a \textbf{BLOCKCIPHER}. We will show that $PRPs \approx PRFs$. 
This will also explain the real-world design of some blockciphers (e.g., DES, AES). 

\section*{CPA-Secure SKE for Variable Length Messages}
Let's start with encryption (CPA-security). 
Recall the CPA indistinguishability game ($\game^{CPA}$): 
The adversary $\mathcal{A}$ submits two messages $m_0, m_1$ of the same length ($|m_0| = |m_1|$) to a challenger. The challenger picks $k \leftarrow \mathcal{K}$, computes $c \leftarrow \enc(k, m_b)$ for a random bit $b$, and sends $c$ to $\mathcal{A}$. $\mathcal{A}$ wins if it guesses $b$.
We need this to work for messages of any polynomial length (VIL). 

\subsection*{Mode of Operation} 
A mode of operation is a standardized way to encrypt messages $m = (m_1, \dots, m_d)$, where $m_i \in \{0,1\}^n$, using a PRF $\mathcal{F} = \{F_k: \{0,1\}^n \rightarrow \{0,1\}^n\}$. 

\begin{rem}
We can't just use $c = (F_k(m_1), \dots, F_k(m_d))$. This is Electronic Codebook (ECB) mode, and it's not secure (it leaks equalities between blocks). This is true even if $F$ is a PRP. 
\end{rem}

\subsubsection*{CBC (Cipher Block Chaining) Mode} 
\begin{itemize}
    \item $c_0 = IV \in U_n$ (Initialization Vector) 
    \item $c_i = F_k(c_{i-1} \oplus m_i)$ for $i=1, \dots, d$ 
    \item Output: $c = (c_0, c_1, \dots, c_d)$ 
\end{itemize}
\begin{center}
    \includegraphics[scale=0.4]{img/Symmetric/CBC.png}
\end{center}
Decryption requires $F_k^{-1}$, so $F$ must be a PRP. Encryption is sequential. 
\begin{thm}
If $F$ is a PRP, then CBC-Mode is CPA-secure for VIL. 
\end{thm}

\subsubsection*{OFB (Output Feedback) Mode} 
\begin{itemize}
    \item $c_0 = r \in U_n$ 
    \item $k_0 = r$
    \item $k_i = F_k(k_{i-1})$ for $i=1, \dots, d$ 
    \item $c_i = k_i \oplus m_i$ for $i=1, \dots, d$ 
    \item Output: $c = (c_0, c_1, \dots, c_d)$
\end{itemize}
\begin{center}
    \includegraphics[scale=0.4]{img/Symmetric/OFB.png}
\end{center}

\subsubsection*{CTR (Counter) Mode} 
\begin{itemize}
    \item $c_0 = r \in U_n$ (where $r$ is a counter) 
    \item $c_i = F_k(r+i-1) \oplus m_i$ for $i=1, \dots, d$ 
    \item Output: $c = (c_0, c_1, \dots, c_d)$
    \item Note: "$+$" can be modulo $2^n$ arithmetic. 
\end{itemize}
\begin{center}
    \includegraphics[scale=0.4]{img/Symmetric/CTR.png}
\end{center}

\begin{thm}
Assuming $F$ is a PRF, CTR mode is a CPA-secure SKE for VIL. 
\end{thm}
\begin{proof}
We use a hybrid argument.
Let $G(\lambda, b) \equiv \game_{\Pi}^{cpa}(\lambda, b)$ be the CPA game where $\Pi$ is CTR mode using $\mathcal{F}$. We want to show $G(\lambda, 0) \approx_c G(\lambda, 1)$. 
Recall that in $G(\lambda,0)$:\\
Upon input an encryption query $m = (m_1, \dots, m_d)$, we return $c = (c_1, \dots, c_d)$ such that $c_0 = r \in U_n$ and $c_i = F_k(r+i-1) \oplus m_i$.\\
For the challenge $m_b^* = (m_{b,1}^*, \dots, m_{b,d^*}^*) (d^* \in \N is the dimension)$, we return $c^* = (c_0^*, \dots, c_{d^*}^*)$ such that $c_0^* = r^* \in U_n$ and $c_i^* = F_k(r^*+i-1) \oplus m_{b,i}^*$.\\
\begin{itemize}
    \item \textbf{Game $G(\lambda, b)$}: Real game.
    \begin{itemize}
        \item Encryption query $m=(m_1, \dots, m_d)$: return $c=(c_0, \dots, c_d)$ where $c_0 = r \in U_n$ and $c_i = F_k(r+i-1) \oplus m_i$. 
        \item Challenge query $m_b^*$: return $c^*=(c_0^*, \dots, c_{d^*}^*)$ where $c_0^* = r^* \in U_n$ and $c_i^* = F_k(r^*+i-1) \oplus m_{b,i}^*$. 
    \end{itemize}
    \item \textbf{Hybrid $H_1(\lambda, b)$}: Same as $G(\lambda, b)$, but replace $F_k(\cdot)$ with a truly random function $R(\cdot)$. 
    \item \textbf{Hybrid $H_2(\lambda)$}: The challenge ciphertext $c^*$ is uniform and independent of $b$. (i.e., $c_0^* = r^*$ and $c_i^* = u_i \oplus m_{b,i}^*$ where $u_i$ are fresh uniform strings. This is equivalent to $c^*$ being $c_0^*$ and $d^*$ fresh uniform strings, which is independent of $b$.)
\end{itemize}

\begin{lem}
$G(\lambda, b) \approx_c H_1(\lambda, b)$ for all $b \in \{0,1\}$.
\end{lem}
\begin{proof}
Standard reduction. Fix $b$. Assume a PPT $\mathcal{A}$ distinguishes $G(\lambda, b)$ and $H_1(\lambda, b)$. We build a PPT adversary $\mathcal{A}_prf$ against the PRF $F$.
\begin{center}
    \includegraphics[scale=0.4]{img/Symmetric/lem1proof.png}
\end{center}
\end{proof}

\begin{lem}
$H_1(\lambda, b) \approx_c H_2(\lambda)$, as long as the number of encryption queries $q(\lambda) = \poly(\lambda)$. 
\end{lem}
\begin{proof}
In $H_1(\lambda, b)$, the challenge ciphertext is created using the values $R(r^*), R(r^*+1), \dots, R(r^*+d^*-1)$. An encryption query $j$ uses values $R(r_j), R(r_j+1), \dots, R(r_j+d_j-1)$. 

Let \textbf{BAD} be the event that any counter value used for the challenge overlaps with any counter value used for any encryption query. 
$$ \text{BAD} = \exists j, i, i' \text{ s.t. } r^*+i' = r_j+i $$ 
($i' \in [0, d^*-1]$, $i \in [0, d_j-1]$)

Conditioned on $\neg \text{BAD}$, all values $r^*+i'$ are "fresh" inputs to the random function $R$. This means all outputs $R(r^*+i')$ are independent and uniformly random. In this case, $c_i^* = R(r^*+i-1) \oplus m_{b,i}^*$ is a one-time pad encryption, and the ciphertext $c^*$ is uniform and independent of $b$. This is exactly $H_2(\lambda)$. 

By the properties of statistical distance:
$$ SD(H_1(\lambda, b); H_2(\lambda)) \le \Pr[\text{BAD}] $$ 

We just need to bound $\Pr[\text{BAD}]$. Let $q = q(\lambda)$ be the number of queries.
Let $\text{BAD}_j$ be the event that the challenge overlaps with query $j$. 
$\Pr[\text{BAD}] = \Pr[\cup_{j=1}^q \text{BAD}_j] \le \sum_{j=1}^q \Pr[\text{BAD}_j]$ (by Union Bound). 

Let's bound $\Pr[\text{BAD}_j]$. WLOG, assume all message lengths are at most $q$. 
Overlap $\text{BAD}_j$ occurs if $\{r^*, \dots, r^*+q-1\}$ overlaps with $\{r_j, \dots, r_j+q-1\}$. 
$r^*$ and $r_j$ are chosen uniformly from $\{0, \dots, 2^n-1\}$.
Overlap happens if $r_j \in [r^*-q+1, r^*+q-1]$. 
The size of this interval is $(r^*+q-1) - (r^*-q+1) + 1 = 2q-1$.
So, $\Pr[\text{BAD}_j] = \frac{2q-1}{2^n}$. 

$$ \Pr[\text{BAD}] \le \sum_{j=1}^q \frac{2q-1}{2^n} = q \cdot \frac{2q-1}{2^n} \le \frac{2q^2}{2^n} = \negl(\lambda) $$ 
Since $q = \poly(\lambda)$ and $n$ (the block size) is related to $\lambda$ (e.g., $n=\lambda$), $2^n$ is exponential in $\lambda$.
\end{proof}

\textbf{Conclusion}:
$G(\lambda, 0) \approx_c H_1(\lambda, 0) \approx_c H_2(\lambda) \approx_c H_1(\lambda, 1) \approx_c G(\lambda, 1)$. 
The advantages $G(\lambda, 0) \approx_c H_1(\lambda, 0)$ and $H_1(\lambda, 1) \approx_c G(\lambda, 1)$ are negligible by Lemma 1.
The advantages $H_1(\lambda, 0) \approx_c H_2(\lambda)$ and $H_2(\lambda) \approx_c H_1(\lambda, 1)$ are negligible by Lemma 2.
Thus, $G(\lambda, 0) \approx_c G(\lambda, 1)$ by the triangle inequality, and CTR mode is CPA-secure. 
\end{proof}

\subsection{Message Authentication Codes (MACs)}

We now switch to the problem of message authentication. 
We need a security guarantee that it is computationally hard to forge a message/tag pair $(m^*, \tau^*)$ such that $\text{Vrfy}(k, m^*) = \text{accept}$ (or $\text{Tag}(k, m^*) = \tau^*$) without knowing the secret key $k$. 

\begin{defn}[UF-CMA]
We say a MAC scheme $\Pi = (\text{Gen}, \text{Tag}, \text{Vrfy})$ is \textbf{Unforgeable Under a Chosen-Message Attack (UF-CMA)} if for all PPT adversaries $\mathcal{A}$, $\Pr[\game_{\Pi, \mathcal{A}}^{ufcma}(\lambda) = 1] \le \negl(\lambda)$. 

The game $\game_{\Pi, \mathcal{A}}^{ufcma}(\lambda)$ proceeds as follows: 
\begin{enumerate}
    \item $k \leftarrow \text{Gen}(\lambda)$ 
    \item $\mathcal{A}$ gets oracle access to $\text{Tag}(k, \cdot)$. $\mathcal{A}$ makes queries $m_1, \dots, m_q$ and receives $\tau_i = \text{Tag}(k, m_i)$. 
    \item $\mathcal{A}$ outputs a pair $(m^*, \tau^*)$. 
    \item $\mathcal{A}$ wins if $\text{Vrfy}(k, m^*) = \text{accept}$ (i.e., $\text{Tag}(k, m^*) = \tau^*$) AND $m^* \notin \{m_1, \dots, m_q\}$. 
\end{enumerate}
\end{defn}

\begin{thm}
If $\mathcal{F} = \{F_k\}$ is a PRF, then the MAC scheme $\text{Tag}(k, m) = F_k(m)$ is UF-CMA for fixed-length messages. 
\end{thm}
\begin{proof}
[Proof of Theorem 14]
We prove this by a standard reduction to the security of the PRF $\mathcal{F}$. We will show that if there exists a PPT adversary $\mathcal{A}$ that can win the UF-CMA game with non-negligible probability $\epsilon(\lambda)$, then we can build a PPT distinguisher $\mathcal{D}$ that can break the PRF security of $\mathcal{F}$ with the same non-negligible advantage.

Recall the PRF security game [cite: 626]: The distinguisher $\mathcal{D}$ is given an oracle $\mathcal{O}$, which is either the real PRF $F_k(\cdot)$ (for a random $k$) [cite: 639] or a truly random function $R(\cdot)$[cite: 640]. $\mathcal{D}$ must output a bit $b'$ guessing which oracle it has. Its advantage is $|Pr[\mathcal{D} \text{ wins} | \mathcal{O}=F_k] - Pr[\mathcal{D} \text{ wins} | \mathcal{O}=R]|$.

Our distinguisher $\mathcal{D}$ will work as follows, using $\mathcal{A}$ as a subroutine:

\begin{enumerate}
    \item $\mathcal{D}$ receives its oracle $\mathcal{O}$ (which is either $F_k$ or $R$).
    \item $\mathcal{D}$ runs the adversary $\mathcal{A}$.
    \item When $\mathcal{A}$ makes a MAC query for a message $m_i$[cite: 865], $\mathcal{D}$ queries its own oracle $\mathcal{O}$ to get $\tau_i = \mathcal{O}(m_i)$. $\mathcal{D}$ then returns $\tau_i$ to $\mathcal{A}$.
    \item $\mathcal{A}$ makes $q = poly(\lambda)$ such queries.
    \item Eventually, $\mathcal{A}$ outputs its forgery attempt $(m^*, \tau^*)$[cite: 866]. By the game rules, $m^* \notin \{m_1, \dots, m_q\}$[cite: 867].
    \item $\mathcal{D}$ must now output its guess. $\mathcal{D}$ queries its oracle $\mathcal{O}$ on $m^*$ to get the "correct" tag $\tau'_{*} = \mathcal{O}(m^*)$.
    \item \textbf{If} $\tau^* = \tau'_{*}$ (meaning $\mathcal{A}$'s forgery was successful), $\mathcal{D}$ outputs $1$ (guessing it has the real PRF).
    \item \textbf{Else} (if the forgery failed), $\mathcal{D}$ outputs $0$ (guessing it has the random function).
\end{enumerate}

\textbf{Explanation of the Reduction:} We are trying to see if $\mathcal{A}$'s success rate changes depending on the oracle $\mathcal{D}$ is given.

\begin{itemize}
    \item \textbf{Case 1: $\mathcal{D}$ has the random function $R(\cdot)$ (Game 1 / H(1) [cite: 9]).}
    In this case, $\mathcal{A}$ is interacting with a truly random function. It queries $m_1, \dots, m_q$ and receives $q$ random values $\tau_1, \dots, \tau_q$. It then outputs $(m^*, \tau^*)$ for a *new* message $m^*$.
    Since $m^*$ has never been queried before, $R(m^*)$ is a fresh, uniformly random value from $\{0,1\}^n$, completely independent of all previous queries.
    The probability that $\mathcal{A}$'s guess $\tau^*$ is equal to this random value is exactly $1 / 2^n$.
    Therefore, $Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}=R] = Pr[\mathcal{A} \text{ wins} | \text{Ideal}] \le \frac{1}{2^n} = negl(\lambda)$.

    \item \textbf{Case 2: $\mathcal{D}$ has the real PRF $F_k(\cdot)$ (Game 0 / G(0) [cite: 5]).}
    In this case, $\mathcal{A}$ is interacting with the real MAC. The probability that $\mathcal{D}$ outputs 1 is exactly the probability that $\mathcal{A}$ wins the real UF-CMA game.
    $Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}=F_k] = Pr[\mathcal{A} \text{ wins} | \text{Real}]$.
    By assumption, $\mathcal{A}$ wins with non-negligible probability $\epsilon(\lambda)$.
    So, $Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}=F_k] = \epsilon(\lambda)$.
\end{itemize}

\textbf{Conclusion:}
The advantage of our distinguisher $\mathcal{D}$ is:
$$ |Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}=F_k] - Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}=R]| $$
$$ = |\epsilon(\lambda) - negl(\lambda)| $$
This advantage is non-negligible. This contradicts the assumption that $\mathcal{F}$ is a secure PRF. Therefore, no such adversary $\mathcal{A}$ can exist, and the MAC is UF-CMA secure.
\end{proof}

\section{Extending MACs to Longer Messages} [cite: 18]
The previous theorem proves security for fixed-length messages, where the message length is the input length of the PRF. But what about variable-length or long messages? [cite: 19]

\subsection{Warm-up: Insecure Constructions} [cite: 21]
Let's analyze a few simple (and bad) ideas for extending a fixed-length MAC $Tag(k, \cdot) = F_k(\cdot)$ to handle a long message $m = (m_1, m_2, \dots, m_d)$.

\subsubsection{Construction 1: Block-by-Block MAC}
Define $Tag(k, m) = (\tau_1, \dots, \tau_d)$ where $\tau_i = F_k(m_i)$[cite: 23].
\begin{itemize}
    \item \textbf{Attack (Splicing / Mix-and-Match):} [cite: 24-25] This construction is not secure. An attacker can perform a "mix-and-match" attack.
    \begin{enumerate}
        \item Attacker queries for the tag on $m = (m_1, m_2)$[cite: 26]. It receives $\tau = (\tau_1, \tau_2)$.
        \item Attacker queries for the tag on $m' = (m_3, m_4)$[cite: 31]. It receives $\tau' = (\tau_3, \tau_4)$.
        \item Attacker can now forge the tag for a new message $m_{new} = (m_1, m_4)$. The forged tag is $\tau_{new} = (\tau_1, \tau_4)$[cite: 31]. This is a valid tag for a message the attacker never queried.
    \end{enumerate}
\end{itemize}

\subsubsection{Construction 2: Simple XOR Sum}
Define $Tag(k, m) = \bigoplus_{i=1}^d F_k(m_i)$[cite: 32].
\begin{itemize}
    \item \textbf{Attack (Reordering / Forgery):} [cite: 37] This is also insecure.
    \begin{enumerate}
        \item Attacker queries for the tag on a one-block message $m = (m_1)$. It receives $\tau = F_k(m_1)$.
        \item Attacker can now forge the tag for the two-block message $m^* = (m_1, m_1)$[cite: 45].
        \item The valid tag would be $\tau^* = F_k(m_1) \oplus F_k(m_1) = 0$.
        \item The attacker outputs $(m^*, 0)$. This is a valid forgery for a new message.
    \end{enumerate}
\end{itemize}

\subsection{A Secure Construction: Hash-then-MAC}
The secure idea is to first hash the long message $m$ into a short, fixed-length string, and then apply our secure fixed-length MAC to that string[cite: 51].

Let $\mathcal{H} = \{h_s: \{0,1\}^nd \rightarrow \{0,1\}^n\}_{s \in \{0,1\}^\lambda}$ be a family of hash functions, where $s$ is a key for the hash function.
Let $\mathcal{F} = \{F_k: \{0,1\}^n \rightarrow \{0,1\}^n\}_{k \in \mathcal{K}}$ be a PRF.

The Hash-then-MAC construction is:
$$ Tag_{(k,s)}(m) = F_k(h_s(m)) $$ [cite: 51]
The full key is the pair $(k, s)$.

\textbf{What property do we need from $\mathcal{H}$?} [cite: 51]
If an attacker can find $m \neq m'$ such that $h_s(m) = h_s(m')$ (a collision) [cite: 54-55], they can break the MAC. They would ask for the tag $\tau = Tag(m) = F_k(h_s(m))$. They would then know that $\tau$ is also the tag for $m'$, a message they never queried.

So, we need $\mathcal{H}$ to be **Collision-Resistant**[cite: 56]. However, this is a strong requirement and can be computationally expensive. We can get away with a weaker, statistical property.

\begin{defn}[$\epsilon$-Almost Universal (AU) Hash Family] [cite: 57-58]
A family of hash functions $\mathcal{H} = \{h_s: \mathcal{M} \rightarrow \mathcal{T}\}_{s \in \mathcal{S}}$ is \textbf{$\epsilon$-Almost Universal} if for all distinct messages $m, m' \in \mathcal{M}$ (with $m \neq m'$)[cite: 59], we have:
$$ Pr_{s \leftarrow \mathcal{S}} [ h_s(m) = h_s(m') ] \le \epsilon $$ [cite: 60-61]
If $\epsilon = 1/|\mathcal{T}|$ (e.g., $2^{-n}$) [cite: 62], the family is called \textbf{Perfectly Universal}[cite: 65]. We only require $\epsilon$ to be a negligible function, $\epsilon = negl(\lambda)$[cite: 67].
\end{defn}

\begin{thm}
If $\mathcal{F}$ is a secure PRF and $\mathcal{H}$ is an $\epsilon$-AU hash family (with $\epsilon = negl(\lambda)$), then the Hash-then-MAC construction $Tag_{(k,s)}(m) = F_k(h_s(m))$ is a UF-CMA secure MAC. [cite: 71]
\end{thm}

\begin{proof}
We use a hybrid argument to prove this. Let $\mathcal{A}$ be a PPT adversary making $q$ queries.
\begin{itemize}
    \item \textbf{Game 0 ($H_0$):} The real game[cite: 76]. The challenger picks random $k \in \mathcal{K}$ and $s \in \mathcal{S}$. $\mathcal{A}$ interacts with an oracle $\mathcal{O}(m) = F_k(h_s(m))$.
    \item \textbf{Game 1 ($H_1$):} The "Hashed Random Function" game[cite: 78]. The challenger picks a random $s \in \mathcal{S}$ and a truly random function $R: \{0,1\}^n \rightarrow \{0,1\}^n$. $\mathcal{A}$ interacts with $\mathcal{O}(m) = R(h_s(m))$.
    \item \textbf{Game 2 ($H_2$):} The "Ideal MAC" game[cite: 81]. The challenger picks a truly random function $R': \{0,1\}^* \rightarrow \{0,1\}^n$. $\mathcal{A}$ interacts with $\mathcal{O}(m) = R'(m)$.
\end{itemize}
We will show that $Pr[\mathcal{A} \text{ wins in } H_0] \approx Pr[\mathcal{A} \text{ wins in } H_1] \approx Pr[\mathcal{A} \text{ wins in } H_2]$, and that $Pr[\mathcal{A} \text{ wins in } H_2]$ is negligible.

\textbf{Step 1: $H_0 \approx_c H_1$} [cite: 82]
This step relies on the security of the PRF $\mathcal{F}$. We can build a distinguisher $\mathcal{D}$ for the PRF game:
\begin{enumerate}
    \item $\mathcal{D}$ receives its oracle $\mathcal{O}'$ (which is either $F_k$ or $R$).
    \item $\mathcal{D}$ simulates $H_0$ or $H_1$ for $\mathcal{A}$. It picks a hash key $s \in \mathcal{S}$ itself.
    \item When $\mathcal{A}$ queries $m_i$, $\mathcal{D}$ computes the digest $d_i = h_s(m_i)$.
    \item $\mathcal{D}$ queries its own oracle $\mathcal{O}'$ to get $\tau_i = \mathcal{O}'(d_i)$ and returns $\tau_i$ to $\mathcal{A}$.
    \item When $\mathcal{A}$ outputs a forgery $(m^*, \tau^*)$, $\mathcal{D}$ computes $d^* = h_s(m^*)$ and checks if $\mathcal{O}'(d^*) = \tau^*$ and $m^*$ is new.
    \item If $\mathcal{A}$ wins, $\mathcal{D}$ outputs 1, else 0.
\end{enumerate}
From $\mathcal{A}$'s perspective, this simulation is perfect.
$Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}'=F_k] = Pr[\mathcal{A} \text{ wins in } H_0]$.
$Pr[\mathcal{D} \text{ outputs } 1 | \mathcal{O}'=R] = Pr[\mathcal{A} \text{ wins in } H_1]$.
By the PRF security, $|Pr[\mathcal{A} \text{ wins in } H_0] - Pr[\mathcal{A} \text{ wins in } H_1]| \le negl(\lambda)$.

\textbf{Step 2: $H_1 \approx H_2$} [cite: 94]
This step relies on the $\epsilon$-AU property of $\mathcal{H}$. We compare $H_1$ (oracle $R(h_s(\cdot))$) and $H_2$ (oracle $R'(\cdot)$).
In $H_2$, every new message $m_i$ maps to a fresh, independent random value $R'(m_i)$.
In $H_1$, this is also true... *unless* a hash collision occurs.

Let **BAD** be the event that a collision occurs among any of the $q$ queries $\mathcal{A}$ makes, or its final forgery $m^*$ (for a total of $q+1$ messages)[cite: 97, 100].
$$ \text{BAD} \equiv \exists i \neq j \in \{1, \dots, q, *\} \text{ s.t. } m_i \neq m_j \text{ and } h_s(m_i) = h_s(m_j) $$
\begin{itemize}
    \item \textbf{If $\neg$BAD occurs (no collision):} Then every distinct message $m_i$ maps to a distinct digest $d_i = h_s(m_i)$. Since $R$ is a random function, $R(d_i)$ is a fresh random value for each $i$. This is *identical* to the behavior of $H_2$. So, $Pr[\mathcal{A} \text{ wins } | \neg\text{BAD}, H_1] = Pr[\mathcal{A} \text{ wins } | \neg\text{BAD}, H_2]$.
    \item The only difference between the games is when BAD occurs. By the "Difference Lemma", the statistical distance between the games is bounded by the probability of this event: $SD(H_1, H_2) \le Pr[\text{BAD}]$[cite: 105].
\end{itemize}

\textbf{Bounding $Pr[\text{BAD}]$:} [cite: 109]
We have $q+1$ messages in total. The number of pairs is $\binom{q+1}{2}$.
We can use a Union Bound over all pairs:
$$ Pr[\text{BAD}] \le \sum_{1 \le i < j \le q+1} Pr[h_s(m_i) = h_s(m_j)] $$ [cite: 112]
By the $\epsilon$-AU property, each term is $\le \epsilon$[cite: 60].
$$ Pr[\text{BAD}] \le \binom{q+1}{2} \cdot \epsilon $$ [cite: 112]
Since $q = poly(\lambda)$ and $\epsilon = negl(\lambda)$, $Pr[\text{BAD}]$ is negligible.
Thus, $Pr[\mathcal{A} \text{ wins in } H_1] \le Pr[\mathcal{A} \text{ wins in } H_2] + Pr[\text{BAD}] \approx Pr[\mathcal{A} \text{ wins in } H_2]$.

\textbf{Step 3: Bounding the Win Probability in $H_2$}
In $H_2$, $\mathcal{A}$ interacts with a truly random function $R'$. It makes $q$ queries and gets $q$ random tags. It then outputs $(m^*, \tau^*)$ for a new message $m^*$. The probability that $\tau^*$ equals the fresh random value $R'(m^*)$ is $1/2^n$.
$Pr[\mathcal{A} \text{ wins in } H_2] \le \frac{1}{2^n} = negl(\lambda)$.

\textbf{Conclusion:}
Putting it all together:
$Pr[\mathcal{A} \text{ wins in } H_0] \approx Pr[\mathcal{A} \text{ wins in } H_1] \approx Pr[\mathcal{A} \text{ wins in } H_2] \le negl(\lambda)$.
Therefore, the probability of winning the real game is negligible.
\end{proof}

\section{Examples of AU Hash Families} [cite: 113]
To use the Hash-then-MAC construction, we need concrete AU hash families.

\subsection{Example 1: Vector Dot Product} [cite: 116]
\begin{itemize}
    \item \textbf{Field:} Let $\mathbb{F} = GF(2^n)$[cite: 114].
    \item \textbf{Messages:} $m = (m_1, \dots, m_d)$ where each $m_i \in \mathbb{F}$.
    \item \textbf{Keys:} $s = (s_1, \dots, s_d)$ where each $s_i \in \mathbb{F}$. The key space $\mathcal{S} = \mathbb{F}^d$[cite: 116].
    \item \textbf{Hash Function:} $h_s(m) = \sum_{i=1}^d s_i \cdot m_i = \langle \vec{s}, \vec{m} \rangle$ [cite: 116] (This is the dot product in $\mathbb{F}$).
\end{itemize}

\textbf{Proof of AU Property:}
We want to calculate $Pr_{s \in \mathbb{F}^d}[h_s(m) = h_s(m')]$ for $m \neq m'$[cite: 121, 123].
$$ h_s(m) = h_s(m') \implies \sum_{i=1}^d s_i m_i = \sum_{i=1}^d s_i m'_i $$
$$ \implies \sum_{i=1}^d s_i (m_i - m'_i) = 0 $$ [cite: 125]
Let $\delta_i = m_i - m'_i$[cite: 119]. Since $m \neq m'$, at least one $\delta_j \neq 0$. Without loss of generality, assume $\delta_1 \neq 0$[cite: 122].
We can now solve for $s_1$:
$$ s_1 \delta_1 = - \sum_{i=2}^d s_i \delta_i $$
Since $\delta_1 \neq 0$, it has a multiplicative inverse in $\mathbb{F}$.
$$ s_1 = (\delta_1)^{-1} \cdot \left( - \sum_{i=2}^d s_i \delta_i \right) $$ [cite: 126]
\textbf{Explanation:} This equation shows that for any possible choice of $s_2, \dots, s_d$ (of which there are $|\mathbb{F}|^{d-1}$ choices), the value of $s_1$ is \textit{uniquely determined} for a collision to occur.
The total number of keys $s \in \mathcal{S}$ is $|\mathbb{F}|^d$.
The number of keys causing a collision for this fixed $m, m'$ is $|\mathbb{F}|^{d-1}$ (since $s_2, \dots, s_d$ can be anything, but $s_1$ is then fixed).
$$ Pr[\text{collision}] = \frac{\text{\# collision keys}}{\text{\# total keys}} = \frac{|\mathbb{F}|^{d-1}}{|\mathbb{F}|^d} = \frac{1}{|\mathbb{F}|} = \frac{1}{2^n} $$ [cite: 127]
This family is $\epsilon$-AU with $\epsilon = 2^{-n}$. It is perfectly universal.

\subsection{Example 2: Polynomial Evaluation} [cite: 130]
\begin{itemize}
    \item \textbf{Field:} Let $\mathbb{F} = GF(2^n)$[cite: 128].
    \item \textbf{Messages:} $m = (m_1, \dots, m_d)$ where each $m_i \in \mathbb{F}$.
    \item \textbf{Keys:} $s \in \mathbb{F}$. The key $s$ is just a single element from the field[cite: 128].
    \item \textbf{Hash Function:} We treat the message blocks $m_i$ as coefficients of a polynomial of degree $d-1$:
    $$ q_m(x) = \sum_{j=1}^d m_j x^{j-1} $$ [cite: 130]
    The hash is the evaluation of this polynomial at the key $s$:
    $$ h_s(m) = q_m(s) $$ [cite: 130]
\end{itemize}

\textbf{Proof of AU Property:}
We want $Pr_{s \in \mathbb{F}}[h_s(m) = h_s(m')]$ for $m \neq m'$[cite: 131].
$$ h_s(m) = h_s(m') \implies q_m(s) = q_{m'}(s) \implies q_m(s) - q_{m'}(s) = 0 $$ [cite: 133]
This is equivalent to:
$$ q_{m-m'}(s) = \sum_{j=1}^d (m_j - m'_j) s^{j-1} = 0 $$ [cite: 134-135]
Let $q_{\delta}(x) = q_{m-m'}(x)$. Since $m \neq m'$, the vector of coefficients $(\delta_1, \dots, \delta_d)$ is not all-zero, so $q_{\delta}(x)$ is a non-zero polynomial.
The degree of $q_{\delta}(x)$ is at most $d-1$[cite: 136].
By the \textbf{Schwartz-Zippel Lemma} (or the fact that a non-zero polynomial of degree $d-1$ over a field can have at most $d-1$ roots), there are at most $d-1$ values of $s \in \mathbb{F}$ that can be a root of $q_{\delta}(x)$.
$$ Pr[\text{collision}] = \frac{\text{\# of roots}}{\text{\# of possible keys}} \le \frac{d-1}{|\mathbb{F}|} = \frac{d-1}{2^n} $$ [cite: 136]
This family is $\epsilon$-AU with $\epsilon = (d-1)/2^n$. This is negligible as long as the number of blocks $d$ is polynomial.

\subsection{Example 3: CBC-MAC as a Hash Function} [cite: 137]
The CBC-MAC construction itself can be viewed as a way to construct an AU hash family[cite: 137].
\begin{itemize}
    \item \textbf{Construction:} Let $\mathcal{F} = \{F_s: \{0,1\}^n \rightarrow \{0,1\}^n\}$ be a PRF family. The hash key is $s$, the PRF key.
    \item Let $m = (m_1, \dots, m_d)$. The CBC-MAC construction is [cite: 141-147]:
    \begin{enumerate}
        \item $t_0 = 0^n$ (a fixed IV)
        \item $t_i = F_s(t_{i-1} \oplus m_i)$ for $i=1, \dots, d$
    \end{enumerate}
    \item \textbf{Hash Function:} $h_s(m) = t_d$.
\end{itemize}

\begin{thm}[Informal]
If $\mathcal{F}$ is a secure PRF, then the CBC-MAC construction (for fixed-length messages $m$ of $d$ blocks) defines a \textbf{computationally $\epsilon$-AU} hash family[cite: 153].
\end{thm}
\textbf{Explanation:} This means that for any $m \neq m'$, the probability $Pr_s[h_s(m) = h_s(m')]$ is negligible. This is a \textit{computational} bound (it relies on the adversary's inability to break the PRF) rather than a purely \textit{statistical} one like the previous two examples. Proving this is more involved but shows that CBC-MAC is a secure method for hashing a long message into a short, pseudorandom tag.

\section{Authenticated Encryption and CCA Security}
So far, we have looked at two goals of symmetric cryptography in isolation:
\begin{itemize}
    \item \textbf{Privacy:} Ensuring messages are confidential (CPA-Secure SKE).
    \item \textbf{Integrity:} Ensuring messages are authentic (UF-CMA MACs).
\end{itemize}
What's left is to combine them. This leads to the strongest notion of security for symmetric key encryption: non-malleability, also known as security against Chosen-Ciphertext Attacks (CCA).

\subsection{Malleability and Chosen-Ciphertext Attacks (CCA)}
\begin{defn}[Malleability]
Malleability is the property of an encryption scheme where an adversary, upon seeing a ciphertext $c$, can modify it to create a new ciphertext $c'$ such that the corresponding plaintext $m'$ is meaningfully related to the original plaintext $m$, even without knowing $m$.
\end{defn}

This is a problem in many applications, such as sealed-bid auctions. If an adversary sees Alice's encrypted bid $c = Enc(k, \text{"100"})$ and can change it to $c' = Enc(k, \text{"99"})$ (a related plaintext), they can win the auction unfairly.

Unfortunately, \textbf{CPA-security does not prevent malleability}.
Consider the following CPA-secure SKE (a variant of CTR mode):
\begin{itemize}
    \item $Enc(k, m) = (r, F_k(r) \oplus m)$, where $r \leftarrow U_n$.
\end{itemize}
An adversary can intercept a ciphertext $c = (c_0, c_1) = (r, F_k(r) \oplus m)$. They can then create a new, "mangled" ciphertext:
$$ \tilde{c} = (c_0, c_1 \oplus \vec{v}) $$
where $\vec{v} = (1, 0, \dots, 0)$ is a vector.
The decryption of $\tilde{c}$ will be:
$$ Dec(k, \tilde{c}) = F_k(c_0) \oplus (c_1 \oplus \vec{v}) = F_k(r) \oplus (F_k(r) \oplus m \oplus \vec{v}) = m \oplus \vec{v} $$
The adversary successfully flipped the first bit of the plaintext without ever knowing what it was. This is a classic malleability attack.

To prevent this, we introduce the formal notion of \textbf{Non-Malleability (NM)}, which is defined using the \textbf{Chosen-Ciphertext Attack (CCA)} security game.

\begin{defn}[CCA Security]
A Symmetric Key Encryption scheme $\Pi = (Enc, Dec)$ is \textbf{secure against Chosen-Ciphertext Attacks (CCA-secure)} if for any PPT adversary $\mathcal{A}$, the advantage in the following game is negligible:
$$ | Pr[GAME_{\Pi, \mathcal{A}}^{CCA}(\lambda, 0) = 1] - Pr[GAME_{\Pi, \mathcal{A}}^{CCA}(\lambda, 1) = 1] | \le negl(\lambda) $$
\end{defn}

The $GAME^{CCA}$ proceeds as follows:
\begin{enumerate}
    \item A key $k \leftarrow \mathcal{K}$ is generated.
    \item The adversary $\mathcal{A}$ is given oracle access to $Enc(k, \cdot)$ and $Dec(k, \cdot)$.
    \item $\mathcal{A}$ makes any number of encryption and decryption queries.
    \item $\mathcal{A}$ submits two challenge messages $m_0^*, m_1^*$ (of equal length).
    \item The challenger picks $b \leftarrow \{0, 1\}$, computes the challenge ciphertext $c^* \leftarrow Enc(k, m_b^*)$, and sends $c^*$ to $\mathcal{A}$.
    \item $\mathcal{A}$ continues to make encryption and decryption queries, with one crucial restriction: \textbf{it cannot ask to decrypt $c^*$ itself}.
    \item $\mathcal{A}$ outputs a guess $b'$. $\mathcal{A}$ wins if $b' = b$.
\end{enumerate}
This is a very strong definition. The adversary gets to see the decryptions of any ciphertext it wants, *except* the one it is trying to break.

\subsection{A General Recipe: CPA + AUTH $\implies$ CCA}
Proving CCA security directly is complex. A simpler "recipe" is to combine two properties: CPA security (which we know) and a new property, \textbf{Authenticity}.

\begin{defn}[Authenticity (AUTH)]
A SKE scheme $\Pi = (Enc, Dec)$ has \textbf{ciphertext authenticity} if it is computationally infeasible for an adversary to produce a new, \textit{valid} ciphertext that it did not see before.
A ciphertext $\tilde{c}$ is \textbf{valid} if $Dec(k, \tilde{c}) \neq \perp$, where $\perp$ is a special error symbol indicating decryption failed.
\end{defn}

We formalize this with the $GAME^{auth}$:
\begin{defn}[AUTH Security]
A SKE $\Pi$ is \textbf{AUTH-secure} if for any PPT adversary $\mathcal{A}$, $Pr[GAME_{\Pi, \mathcal{A}}^{auth}(\lambda) = 1] \le negl(\lambda)$.
\end{defn}
The $GAME^{auth}$ proceeds as follows:
\begin{enumerate}
    \item A key $k \leftarrow \mathcal{K}$ is generated.
    \item $\mathcal{A}$ is given oracle access to $Enc(k, \cdot)$. Let $Q = \{(m_i, c_i)\}$ be the set of query/response pairs.
    \item $\mathcal{A}$ outputs a new ciphertext $\tilde{c}$.
    \item $\mathcal{A}$ wins if $\tilde{c} \notin \{c_1, \dots, c_q\}$ (it's a new ciphertext) AND $Dec(k, \tilde{c}) \neq \perp$ (it's valid).
\end{enumerate}

\begin{thm}
If a SKE scheme $\Pi$ is both \textbf{CPA-secure} and \textbf{AUTH-secure}, then it is \textbf{CCA-secure}.
\end{thm}

\begin{proof}[Proof Sketch]
We prove this by reduction. Assume, for contradiction, that an adversary $\mathcal{A}_{CCA}$ can break the $CCA$ security of $\Pi$. We will show that this implies $\Pi$ is either not $CPA$-secure or not $AUTH$-secure.

We construct a $CPA$ adversary $\mathcal{A}_{CPA}$ that uses $\mathcal{A}_{CCA}$ as a subroutine. $\mathcal{A}_{CPA}$ will simulate the $CCA$ game for $\mathcal{A}_{CCA}$.
\begin{itemize}
    \item \textbf{Challenger:} $\mathcal{C}_{CPA}$ (the $CPA$ challenger).
    \item \textbf{Reducer:} $\mathcal{A}_{CPA}$ (our reduction).
    \item \textbf{Adversary:} $\mathcal{A}_{CCA}$ (the adversary we assume exists).
\end{itemize}

\textbf{The Simulation:}
$\mathcal{A}_{CPA}$ simulates the $GAME^{CCA}$ for $\mathcal{A}_{CCA}$:
\begin{enumerate}
    \item \textbf{Encryption Queries:} When $\mathcal{A}_{CCA}$ asks to encrypt $m_i$, $\mathcal{A}_{CPA}$ passes $m_i$ to its own $CPA$ oracle, $\mathcal{C}_{CPA}$, and gets back $c_i$. $\mathcal{A}_{CPA}$ returns $c_i$ to $\mathcal{A}_{CCA}$. $\mathcal{A}_{CPA}$ stores the pair $(m_i, c_i)$.
    \item \textbf{Challenge Query:} When $\mathcal{A}_{CCA}$ submits $m_0^*, m_1^*$, $\mathcal{A}_{CPA}$ passes them to $\mathcal{C}_{CPA}$ and gets back the challenge $c^*$. $\mathcal{A}_{CPA}$ gives $c^*$ to $\mathcal{A}_{CCA}$.
    \item \textbf{Decryption Queries:} When $\mathcal{A}_{CCA}$ asks to decrypt $\tilde{c}$, $\mathcal{A}_{CPA}$ must answer. It does not have a real decryption oracle.
        \begin{itemize}
            \item \textbf{Rule 1:} If $\tilde{c} = c^*$, $\mathcal{A}_{CPA}$ returns $\perp$ (as per $GAME^{CCA}$ rules).
            \item \textbf{Rule 2:} If $\tilde{c}$ is on its list of known ciphertexts (i.e., $\tilde{c} = c_i$ for some $i$), $\mathcal{A}_{CPA}$ returns the corresponding $m_i$.
            \item \textbf{Rule 3:} If $\tilde{c}$ is new (not $c^*$ and not $c_i$), $\mathcal{A}_{CPA}$ returns $\perp$.
        \end{itemize}
    \item \textbf{Guess:} $\mathcal{A}_{CCA}$ outputs a guess $b'$. $\mathcal{A}_{CPA}$ outputs the same $b'$.
\end{enumerate}

\textbf{Analysis of the Reduction:}
Let $G_{CCA}$ be the real $CCA$ game, and $G'$ be the simulated game $G'$ run by $\mathcal{A}_{CPA}$.
The simulation in $G'$ is perfect, \textit{unless} Rule 3 fails.
Rule 3 fails if $\mathcal{A}_{CCA}$ submits a new ciphertext $\tilde{c}$ for which the \textit{real} answer is $Dec(k, \tilde{c}) = m' \neq \perp$.
Let's call this the **BAD** event.
$$ \text{BAD} \equiv \mathcal{A}_{CCA} \text{ queries } \tilde{c} \notin \{c_1, \dots, c_q\} \text{ s.t. } Dec(k, \tilde{c}) \neq \perp $$
This is \textit{exactly} the winning condition for the $GAME^{auth}$!
Because $\Pi$ is $AUTH$-secure, we know $Pr[BAD] \le negl(\lambda)$.

By the Difference Lemma, the adversary's advantage can only differ by at most $Pr[BAD]$:
$$ | Adv_{G_{CCA}}(\mathcal{A}_{CCA}) - Adv_{G'}(\mathcal{A}_{CCA}) | \le Pr[BAD] \le negl(\lambda) $$
So, $Adv_{G_{CCA}}(\mathcal{A}_{CCA}) \approx Adv_{G'}(\mathcal{A}_{CCA})$.

Now, look at the game $G'$. In $G'$, the decryption oracle is useless: it either returns $\perp$ or information $\mathcal{A}_{CCA}$ already knew (the $m_i$ for a $c_i$). It provides no new information.
Therefore, the game $G'$ is effectively just the $CPA$ game.
$$ Adv_{G'}(\mathcal{A}_{CCA}) = Adv_{CPA}(\mathcal{A}_{CPA}) $$
Because $\Pi$ is $CPA$-secure, we know $Adv_{CPA}(\mathcal{A}_{CPA}) \le negl(\lambda)$.

By the triangle inequality:
$$ Adv_{G_{CCA}}(\mathcal{A}_{CCA}) \approx Adv_{G'}(\mathcal{A}_{CCA}) = Adv_{CPA}(\mathcal{A}_{CPA}) \le negl(\lambda) $$
Therefore, the advantage of $\mathcal{A}_{CCA}$ in the real $CCA$ game must be negligible.
\end{proof}

\subsection{Constructions for Authenticated Encryption}
We now know that $CCA \iff CPA + AUTH$. How do we build a scheme that is both?
The idea is to combine a CPA-secure SKE (let's call it $Enc$) and a UF-CMA MAC (let's call it $Tag$). We need two independent keys, $k_e$ for $Enc$ and $k_m$ for $Tag$.

There are three main ways to combine them:

\subsubsection{Method 1: Encrypt-and-MAC (E\&M)}
We encrypt and MAC the \textit{plaintext} in parallel.
$$ c' = (c, \tau) \quad \text{where} \quad c \leftarrow Enc(k_e, m) \quad \text{and} \quad \tau \leftarrow Tag(k_m, m) $$
\textbf{This is not secure}. It fails to provide CPA security.
\textbf{Why?} The $Tag$ function is applied to $m$. If the $Tag$ function is deterministic, an adversary can check if two plaintexts are equal. $Enc$ is randomized to prevent this, but $\tau$ leaks the information. For example, if $\mathcal{A}$ encrypts $m_0$ and $m_1$ and sees $(c_0, \tau_0)$ and $(c_1, \tau_1)$, if $\tau_0 = \tau_1$, it knows $m_0=m_1$. This breaks the $CPA$ game.

\subsubsection{Method 2: MAC-then-Encrypt (M\&E)}
We MAC the plaintext, then encrypt \textit{both}.
$$ c' \leftarrow Enc(k_e, m || \tau) \quad \text{where} \quad \tau \leftarrow Tag(k_m, m) $$
\textbf{This is not secure}. This construction can fail $AUTH$.
\textbf{Why?} The $Enc$ scheme only guarantees privacy (CPA), not integrity. An SKE scheme might be malleable.
For example, consider a bad SKE: $Enc(k, m || \tau) = (Enc(k, m), \tau)$. This is CPA-secure.
But the $Dec$ function, $Dec(k, (c, \tau'))$, might just decrypt $c$ and ignore $\tau'$. An attacker could flip bits in $\tau'$, and the ciphertext would still decrypt to a valid $m$, failing the $AUTH$ property.

\subsubsection{Method 3: Encrypt-then-MAC (EtM)}
We encrypt the plaintext first, then MAC the \textit{ciphertext}. This is the secure method.
\begin{itemize}
    \item $Enc'( (k_e, k_m), m)$:
        \begin{enumerate}
            \item $c \leftarrow Enc(k_e, m)$
            \item $\tau \leftarrow Tag(k_m, c)$
            \item Output $c' = (c, \tau)$
        \end{enumerate}
    \item $Dec'( (k_e, k_m), c'=(c, \tau) )$:
        \begin{enumerate}
            \item If $Vrfy(k_m, c, \tau) \neq \text{accept}$, output $\perp$.
            \item Else, $m \leftarrow Dec(k_e, c)$.
            \item Output $m$.
        \end{enumerate}
\end{itemize}

\begin{thm}
The \textbf{Encrypt-then-MAC (EtM)} construction is $CCA$-secure, provided that $\Pi_{SKE}$ is $CPA$-secure and $\Pi_{MAC}$ is a $UF-CMA$ MAC (with unique/deterministic tags).
\end{thm}

\begin{proof}[Proof Sketch]
We prove $CPA + AUTH$, which implies $CCA$.
\begin{enumerate}
    \item \textbf{Proof of $CPA$ Security:}
    We build a reduction $\mathcal{A}_{CPA-SKE}$ that breaks the $CPA$ security of
    \begin{itemize}
        \item $\mathcal{A}_{CPA-SKE}$ (the reducer) gets a $CPA$ oracle from its challenger.
        \item To simulate the $EtM$ game, $\mathcal{A}_{CPA-SKE}$ needs to produce tags. It picks its own MAC key $k_m$.
        \item \textbf{Encryption Query $m$:} $\mathcal{A}_{CPA-SKE}$ gets $c$ from its oracle, computes $\tau = Tag(k_m, c)$ itself, and returns $(c, \tau)$.
        \item \textbf{Challenge Query $m_0^*, m_1^*$:} $\mathcal{A}_{CPA-SKE}$ passes this up to its oracle, gets back $c^*$, computes $\tau^* = Tag(k_m, c^*)$, and returns $(c^*, \tau^*)$.
        \item \textbf{Guess:} $\mathcal{A}_{CPA-SKE}$ outputs whatever $\mathcal{A}_{CPA-EtM}$ outputs.
        \item \textbf{Analysis:} This simulation is perfect. The tag $\tau$ is computed on an already-encrypted ciphertext $c$, so it leaks no information about $m$ that $c$ didn't already leak. The advantage is identical. $Adv_{CPA-EtM} = Adv_{CPA-SKE} \le negl(\lambda)$.
    \end{itemize}

    \item \textbf{Proof of $AUTH$ Security:}
    We build a reduction $\mathcal{A}_{UF-CMA}$ that breaks the $UF-CMA$ security of $Tag$ if an adversary $\mathcal{A}_{AUTH}$ breaks $EtM$.
    \begin{itemize}
        \item $\mathcal{A}_{UF-CMA}$ (the reducer) gets a $Tag$ oracle from its challenger.
        \item To simulate the $EtM$ game, $\mathcal{A}_{UF-CMA}$ needs to encrypt. It picks its own SKE key $k_e$.
        \item \textbf{Encryption Query $m$:} $\mathcal{A}_{UF-CMA}$ computes $c = Enc(k_e, m)$ itself. It then queries its $Tag$ oracle $\mathcal{O}_{Tag}(c)$ to get $\tau$. It returns $(c, \tau)$.
        \item \textbf{Adversary Forgery:} $\mathcal{A}_{AUTH}$ outputs a forgery $(\tilde{c}, \tilde{\tau})$.
        \item \textbf{Reducer Forgery:} $\mathcal{A}_{UF-CMA}$ outputs $(\tilde{c}, \tilde{\tau})$ as its own forgery.
        \item \textbf{Analysis:}
            \begin{itemize}
                \item $\mathcal{A}_{AUTH}$ wins if $(\tilde{c}, \tilde{\tau})$ is new AND $Dec(k_e, \tilde{c}) \neq \perp$.
                \item $\mathcal{A}_{UF-CMA}$ wins if $Vrfy(k_m, \tilde{c}) = \tilde{\tau}$ AND $\tilde{c}$ is new (assuming standard UF-CMA, since $\tilde{c}$ is the "message" for the MAC).
            \end{itemize}
        \item The $Dec'$ algorithm for $EtM$ \textit{first} checks the tag. $Dec(k_e, \tilde{c}) \neq \perp$ can only happen if $Vrfy(k_m, \tilde{c}, \tilde{\tau}) = \text{accept}$.
        \item We just need to check that the "newness" conditions align.
        \item $\mathcal{A}_{AUTH}$ queries $m_i \to (c_i, \tau_i)$. $\mathcal{A}_{UF-CMA}$ queries $c_i \to \tau_i$.
        \item $\mathcal{A}_{AUTH}$ outputs $(\tilde{c}, \tilde{\tau}) \notin \{(c_i, \tau_i)\}$.
        \item If the $Tag$ is deterministic ("UNIQUE TAGS"), then it's impossible to have $\tilde{c} = c_i$ but $\tilde{\tau} \neq \tau_i$ and $Vrfy = \text{accept}$.
        \item Therefore, any valid forgery from $\mathcal{A}_{AUTH}$ *must* have $\tilde{c} \notin \{c_i\}$.
        \item This is exactly the winning condition for $\mathcal{A}_{UF-CMA}$!
        \item Thus, $Pr[\mathcal{A}_{AUTH} \text{ wins}] \le Pr[\mathcal{A}_{UF-CMA} \text{ wins}] \le negl(\lambda)$.
    \end{itemize}
\end{enumerate}
Since $EtM$ is both $CPA$-secure and $AUTH$-secure, it is $CCA$-secure.
\end{proof}
\end{document}